{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据使用 postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 envirmonment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "import pymongo\n",
    "import tqdm\n",
    "import psycopg\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATABASE = pymongo.MongoClient(\"192.168.1.222\").temporary_token_similarity\n",
    "\n",
    "\n",
    "\n",
    "collection_node = DATABASE.token_similarity_node_v20240815\n",
    "\n",
    "collection_edge = DATABASE.token_similarity_edge_v20240815\n",
    "\n",
    "pg_uri = os.environ.get('postgres_uri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到集合所有的边\n",
    "def query_distance(tuple_set_1, tuple_set_2):\n",
    "    pg_uri = os.environ.get('postgres_uri')\n",
    "    ret = set()\n",
    "    with psycopg.connect(pg_uri) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            try:\n",
    "                for x in tuple_set_1:\n",
    "                    greater_than_or_equal_x = list(item for item in tuple_set_2 if item > x)\n",
    "                    if greater_than_or_equal_x:\n",
    "                        cursor.execute(\"SELECT source_id,target_id,weight FROM edges WHERE source_id = %s AND target_id = ANY(%s);\", \n",
    "                                    (x, greater_than_or_equal_x,)\n",
    "                                    ) \n",
    "                        for result in cursor:\n",
    "                            ret.add(result)\n",
    "                if tuple_set_1 != tuple_set_2:\n",
    "                    for x in tuple_set_2:\n",
    "                        greater_than_or_equal_x = list(item for item in tuple_set_1 if item > x)\n",
    "                        if greater_than_or_equal_x:\n",
    "                            cursor.execute(\"SELECT source_id,target_id,weight FROM edges WHERE source_id = %s AND target_id = ANY(%s);\", \n",
    "                                        (x, greater_than_or_equal_x,)\n",
    "                                        ) \n",
    "                            for result in cursor:\n",
    "                                ret.add(result)\n",
    "                else:\n",
    "                    pass\n",
    "                    # print(\"dup set\")\n",
    "            except TypeError as e:\n",
    "                print(tuple_set_1)\n",
    "                print(tuple_set_2)\n",
    "                raise e\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 节点子图 加入数据组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 节点集合\n",
    "\n",
    "collection_subject = DATABASE.token_similarity_v20240729\n",
    "subject_id_set = set()\n",
    "for doc in collection_subject.find():\n",
    "    subject_id_set.add(doc['SID'])\n",
    "    subject_id_set.add(doc['EID'])\n",
    "print(len(subject_id_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "edge_list = []\n",
    "node_list = []\n",
    "# id_list = list(subject_id_set)[:100]\n",
    "for s,t,weight in query_distance(subject_id_set,subject_id_set):\n",
    "    edge_list.append({\n",
    "        '_id': f\"{s}-{t}\",\n",
    "        \"s\": s,\n",
    "        \"t\": t,\n",
    "        \"weight\": weight\n",
    "    })\n",
    "    node_list.append({\n",
    "        '_id': s\n",
    "    })\n",
    "    node_list.append({\n",
    "        '_id': t\n",
    "    })\n",
    "\n",
    "try:\n",
    "    collection_edge.insert_many(edge_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)\n",
    "try:\n",
    "    collection_node.insert_many(node_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.1 1M edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 节点集合\n",
    "\n",
    "collection_subject = DATABASE.token_similarity_v20240712\n",
    "subject_id_set = set()\n",
    "\n",
    "pg_uri = os.environ.get('postgres_uri')\n",
    "    \n",
    "with psycopg.connect(pg_uri) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        \n",
    "        for doc in tqdm.tqdm(collection_subject.find()):\n",
    "            if doc['SID'] < doc['EID']:\n",
    "                sid,eid = doc['SID'],doc['EID']\n",
    "            else:\n",
    "                sid,eid = doc['EID'],doc['SID']\n",
    "                \n",
    "            cursor.execute(\"SELECT source_id,target_id,weight FROM edges WHERE source_id = %s AND target_id = %s;\", \n",
    "                        (sid,eid,)\n",
    "                        ) \n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                s,t,weight = result\n",
    "        \n",
    "                edge_list.append({\n",
    "                    '_id': f\"{s}-{t}\",\n",
    "                    \"s\": s,\n",
    "                    \"t\": t,\n",
    "                    \"weight\": weight\n",
    "                })\n",
    "                node_list.append({\n",
    "                    '_id': s\n",
    "                })\n",
    "                node_list.append({\n",
    "                    '_id': t\n",
    "                })\n",
    "\n",
    "try:\n",
    "    collection_edge.insert_many(edge_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)\n",
    "try:\n",
    "    collection_node.insert_many(node_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 均匀数据, 加入实验组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 有索引的查询方法, 不适应没有索引的遍历\n",
    "def query_gpc_limit_by_weight(weight_gt,weight_lte,fetch_size):\n",
    "    with psycopg.connect(pg_uri) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT source_id,target_id,weight FROM edges WHERE weight > %s AND weight <= %s LIMIT %s;\", \n",
    "                        (weight_gt,weight_lte,fetch_size,)\n",
    "                        ) \n",
    "            for result in cursor:\n",
    "                yield result\n",
    "\n",
    "mutiple=10000\n",
    "delta = 1/mutiple\n",
    "edge_list = []\n",
    "node_list = []\n",
    "for i in tqdm.tqdm(range(mutiple)):\n",
    "    gt = i/10000\n",
    "    \n",
    "    for doc in  query_gpc_limit_by_weight(gt,gt+delta,100):\n",
    "\n",
    "        edge_list.append({\n",
    "            '_id':  f\"{doc[0]}-{doc[1]}\",\n",
    "            \"s\": doc[0],\n",
    "            \"t\": doc[1],\n",
    "            \"weight\": doc[2]\n",
    "        })\n",
    "        node_list.append({\n",
    "            '_id': doc[0]\n",
    "        })\n",
    "        node_list.append({\n",
    "            '_id': doc[1]\n",
    "        })\n",
    "        \n",
    "random.shuffle(edge_list)\n",
    "try:\n",
    "    collection_edge.insert_many(edge_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)\n",
    "try:\n",
    "    collection_node.insert_many(node_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)\n",
    "    \n",
    "print(len(edge_list))\n",
    "print(len(node_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 遍历搜索,适合没有索引的表\n",
    "import collections\n",
    "\n",
    "def test():\n",
    "    edge_count = 1000*(1000-5)\n",
    "    edge_count_book = collections.defaultdict(int)\n",
    "    edge_list = []\n",
    "    node_list = []\n",
    "    \n",
    "    def save_data():\n",
    "        random.shuffle(edge_list)\n",
    "        try:\n",
    "            collection_edge.insert_many(edge_list,ordered=False)\n",
    "        except pymongo.errors.BulkWriteError as bwe:\n",
    "            print(bwe.details)\n",
    "        try:\n",
    "            collection_node.insert_many(node_list,ordered=False)\n",
    "        except pymongo.errors.BulkWriteError as bwe:\n",
    "            print(bwe.details)\n",
    "    \n",
    "    with psycopg.connect(pg_uri) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            \n",
    "            gen = cursor.stream(\"SELECT source_id,target_id,weight FROM edges;\") \n",
    "\n",
    "            for s,t,weight in  tqdm.tqdm(gen):\n",
    "                index = int(weight*1000)\n",
    "                if index >= 1000 or edge_count_book[index] > 1000:\n",
    "                    continue\n",
    "\n",
    "                edge_count_book[index] += 1\n",
    "                edge_count -= 1\n",
    "                \n",
    "                edge_list.append({\n",
    "                    '_id':  f\"{s}-{t}\",\n",
    "                    \"s\": s,\n",
    "                    \"t\": t,\n",
    "                    \"weight\": weight\n",
    "                })\n",
    "                node_list.append({\n",
    "                    '_id': s\n",
    "                })\n",
    "                node_list.append({\n",
    "                    '_id': t\n",
    "                })\n",
    "    \n",
    "                if edge_count <= 0:\n",
    "                    print('over')\n",
    "                    save_data()\n",
    "                    \n",
    "                    \n",
    "                    return\n",
    "            save_data()\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 补全 title , description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109306it [10:49, 168.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "def get_plaintext(pageID):\n",
    "    ES = Elasticsearch( \"http://192.168.1.227:9200\")\n",
    "    response = ES.search(\n",
    "        index=\"en_page\",\n",
    "        body={\n",
    "            \"_source\": [\"title\", \"id\", \"plaintext\"],\n",
    "            \"query\": {\n",
    "                \"match_phrase\": {\n",
    "                    \"_id\": pageID,\n",
    "                },\n",
    "            },\n",
    "            \"size\": 1,\n",
    "        },\n",
    "    )\n",
    "    if response[\"hits\"][\"hits\"]:\n",
    "        source = response[\"hits\"][\"hits\"][0]['_source']\n",
    "        text_split  = source.get(\"plaintext\",\"\").strip().split(\"\\n\")\n",
    "        title = source.get(\"title\",\"\").strip()\n",
    "        if text_split:\n",
    "            plain_text = \"\"\n",
    "            for text in text_split:\n",
    "                plain_text += f\"{text} \" \n",
    "                if len(plain_text.strip().split(\" \")) > 15:\n",
    "                    return plain_text.strip(), title\n",
    "            return plain_text,title\n",
    "    return None,title\n",
    "\n",
    "for doc in tqdm.tqdm(collection_node.find({'status': {'$ne':'miss'},'title':None})):\n",
    "    plaintext, title = get_plaintext(doc['_id'])\n",
    "    if not plaintext:\n",
    "        print('plaintext miss')\n",
    "        collection_node.update_one({'_id': doc['_id']}, {'$set': {'status': 'miss'}})\n",
    "        continue\n",
    "    collection_node.update_one({'_id': doc['_id']}, {'$set': {'title': title, 'plaintext': plaintext}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 分词,对 plaintext 提取分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:01, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007 Vallelunga Superbike World Championship round\n",
      "List of doping cases in sport (J)\n",
      "1978–79 Aberdeen F.C. season\n",
      "1977–78 Aberdeen F.C. season\n",
      "1975–76 Aberdeen F.C. season\n",
      "1972–73 Aberdeen F.C. season\n",
      "1971–72 Aberdeen F.C. season\n",
      "1973–74 Aberdeen F.C. season\n",
      "Büyükdere Avenue\n",
      "Boston Society of Film Critics Award for Best Cinematography\n",
      "19th century in poetry\n",
      "1892 in paleontology\n",
      "Boston Society of Film Critics Award for Best Use of Music in a Film\n",
      "Inhospitable\n",
      "1889 in paleontology\n",
      "1963 in spaceflight\n",
      "HLA-Cw7\n",
      "List of titled noble families in the Kingdom of Hungary\n",
      "John S. Dugdale\n",
      "Donald J. Stewart\n",
      "Coeval\n",
      "1965 in spaceflight\n",
      "Secund\n",
      "1879 in paleontology\n",
      "Exoteric\n",
      "Third degree (interrogation)\n",
      "Ecclesiastical\n",
      "National Register of Historic Places listings in South and Southwest Portland, Oregon\n",
      "Webmaster\n",
      "Rhine–Main–Danube Canal\n",
      "Caput\n",
      "List of Latin phrases (P)\n",
      "Abaxial\n",
      "Floristics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../gpc_demo\")\n",
    "from utils import (\n",
    "        get_token,\n",
    ")\n",
    "\n",
    "for doc in tqdm.tqdm(collection_node.find({'status': {'$ne':'miss'},'token':None})):\n",
    "    token,_ = get_token(doc['plaintext'])\n",
    "    token_list = [item[0] for item in token]\n",
    "    if token_list:\n",
    "        collection_node.update_one({'_id':doc['_id']},{'$set':{'token':token_list}})\n",
    "    else:\n",
    "        print(doc['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 计算 node 中的 token 的联通度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "416473it [00:06, 64498.43it/s]\n",
      "100%|██████████| 416473/416473 [11:34:12<00:00, 10.00it/s]  \n"
     ]
    }
   ],
   "source": [
    "doc_list = [doc for doc in tqdm.tqdm(collection_node.find({'token': {'$ne':None},'token_graph':None}))]\n",
    "\n",
    "for doc in tqdm.tqdm(doc_list):\n",
    "    token = doc['token']\n",
    "    edges = [(a,b,weight) for a,b,weight in query_distance(token,token)]\n",
    "    collection_node.update_one({'_id': doc['_id']}, {'$set': {'token_graph': edges}})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 计算 edge 两个 node 之间的 token_graph 之间的边\n",
    "\n",
    "transfer to worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in tqdm.tqdm(collection_edge.find({'graph_link': {'$exists': False}, })):\n",
    "#     sID = doc['s']\n",
    "#     tID = doc['t']\n",
    "#     sdoc = collection_node.find_one({'_id': sID})\n",
    "#     tdoc = collection_node.find_one({'_id': tID})\n",
    "#     sToken = set(sdoc.get('token'))\n",
    "#     tToken = set(tdoc.get('token'))\n",
    "#     if not sToken or not tToken:\n",
    "#         print(\"edge disable\", doc)\n",
    "#         continue\n",
    "    \n",
    "#     edges = [(a,b,weight) for a,b,weight in query_distance(sToken-tToken,tToken-sToken)]\n",
    "#     # print(len(edges))\n",
    "#     # print(len(sToken-tToken))\n",
    "#     # print(len(tToken-sToken))\n",
    "#     # print(edges)\n",
    "    \n",
    "    \n",
    "#     # print(sToken-tToken)\n",
    "#     # print(tToken-sToken)\n",
    "#     collection_edge.update_one(\n",
    "#         {'_id': doc['_id']},\n",
    "#         {'$set': {'graph_link': edges}}\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
