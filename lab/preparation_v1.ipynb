{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (4.8.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from pymongo) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理准备 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "import pymongo\n",
    "import neo4j\n",
    "import tqdm\n",
    "\n",
    "DATABASE = pymongo.MongoClient(\"192.168.1.222\").temporary_token_similarity\n",
    "\n",
    "Collection = DATABASE.token_similarity_v20240815\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import tqdm\n",
    "\n",
    "# # 使用相对路径添加父目录到搜索路径\n",
    "# sys.path.append(\"../gpc_demo\") \n",
    "# sys.path.append(\"..\") \n",
    "\n",
    "# from utils import calculate_cartesian_product_similarity, get_token, search_wikipedia, get_plaintext, calculate_similarity,query_partner_distancles\n",
    "\n",
    "\n",
    "# from modelscope import AutoModel\n",
    "# JinNaAI_Model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99927\n"
     ]
    }
   ],
   "source": [
    "# function\n",
    "\n",
    "# 按 google distance 获取样本数据\n",
    "def query_gpc_limit_by_weight(weight_gt,weight_lte,fetch_size):\n",
    "    driver = neo4j.GraphDatabase.driver(\n",
    "            \"bolt://192.168.1.229:17688\",\n",
    "            auth=(\"neo4j\", \"neo4j-test\"),\n",
    "        )\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (start:P)-[r:D]->(end:P) \"\n",
    "            \"WHERE r.weight > $weight_gt AND r.weight <= $weight_lte \"\n",
    "            \"WITH start.Id as SID, start.Title as Stitle, end.Id as EID, end.Title as Etitle, r.weight as weight \"\n",
    "            \"LIMIT $fetch_size \"\n",
    "            \"RETURN SID, Stitle, EID, Etitle, weight\"\n",
    "            ,\n",
    "            weight_gt=weight_gt,\n",
    "            weight_lte=weight_lte,\n",
    "            fetch_size=fetch_size\n",
    "        )\n",
    "        for record in result:\n",
    "            yield record\n",
    "\n",
    "mutiple=10000\n",
    "delta = 1/mutiple\n",
    "edge_list = []\n",
    "node_list = []\n",
    "for i in range(0,mutiple+1):\n",
    "    gt = i/10000\n",
    "    \n",
    "    for doc in  query_gpc_limit_by_weight(gt,gt+delta,10):\n",
    "        doc = dict(doc)\n",
    "        doc['_id'] = f\"{doc['SID']}-{doc['EID']}\"\n",
    "        edge_list.append(doc)\n",
    "        node_list.append({\n",
    "            '_id': doc['SID']\n",
    "        })\n",
    "try:\n",
    "    collection_edge.insert_many(edge_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)\n",
    "print(len(edge_list))\n",
    "edge_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720059"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 计算 title partner 的 token simmlarity, sts simmlarity {相似度如何}, 将结果update到 v1 key中 \n",
    "\n",
    "from scipy.spatial.distance import (\n",
    "    cosine,\n",
    "    euclidean,\n",
    "    minkowski,\n",
    "    cityblock,\n",
    "    chebyshev,\n",
    ")\n",
    "\n",
    "doc_list = []\n",
    "for doc in Collection.find({'v1':None,'status':None}):\n",
    "    doc_list.append(doc)\n",
    "len(doc_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SID, Stitle, EID, Etitle, weight\n",
    "for doc in tqdm.tqdm(doc_list[25:]):\n",
    "\n",
    "    plaintext_b = get_plaintext(doc['EID'])\n",
    "    plaintext_a = get_plaintext(doc['SID'])\n",
    "    \n",
    "    if not plaintext_a or not plaintext_b:\n",
    "        print('text miss')\n",
    "        Collection.update_one({'_id': doc['_id']}, {'$set': {'status': 'text miss'}})\n",
    "        continue\n",
    "    \n",
    "    if len(plaintext_a.split(\" \"))<=15 or len(plaintext_b.split(\" \"))<=15:\n",
    "        print('text short', end=\" \")\n",
    "        # print(plaintext_a)\n",
    "        # print(plaintext_b)\n",
    "        Collection.update_one({'_id': doc['_id']}, {'$set': {'status': 'text short'}})\n",
    "        continue\n",
    "    \n",
    "    token_set_1, _ = get_token(plaintext_a)\n",
    "    token_set_2, _ = get_token(plaintext_b)\n",
    "    \n",
    "    df, _ = calculate_cartesian_product_similarity(\n",
    "            tuple(token_set_1 - token_set_2), \n",
    "            tuple(token_set_2 - token_set_1),\n",
    "            tuple(token_set_2 & token_set_1),\n",
    "        )\n",
    "    if not len(df):\n",
    "        print('lost tokens')\n",
    "        Collection.update_one({'_id': doc['_id']}, {'$set': {'status': 'lost tokens'}})\n",
    "        continue\n",
    "    \n",
    "    token_similarity = df['similarity'].mean()\n",
    "    embeddings = JinNaAI_Model.encode([plaintext_a, plaintext_b])\n",
    "    cosine_similarity = cosine(embeddings[0],embeddings[1])\n",
    "    euclidean_similarity = euclidean(embeddings[0],embeddings[1])\n",
    "    minkowski_similarity = minkowski(embeddings[0],embeddings[1])\n",
    "    cityblock_similarity = cityblock(embeddings[0],embeddings[1])\n",
    "    chebyshev_similarity = chebyshev(embeddings[0],embeddings[1])\n",
    "    \n",
    "    Collection.update_one({'_id': doc['_id']},{\"$set\":{\n",
    "        'v1':{\n",
    "            'token':token_similarity.item(),\n",
    "            'cosine': cosine_similarity.item(),\n",
    "            'euclidean': euclidean_similarity,\n",
    "            'minkowski': minkowski_similarity,\n",
    "            'cityblock': cityblock_similarity.item(),\n",
    "            'chebyshev': chebyshev_similarity.item(),\n",
    "        }\n",
    "    }})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从数据库中获取已经处理好的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981425"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "DATABASE = pymongo.MongoClient(\"192.168.1.222\").temporary_token_similarity\n",
    "\n",
    "Collection = DATABASE.token_similarity_v20240712\n",
    "\n",
    "doc_list = []\n",
    "for doc in Collection.find({'v1':{\"$exists\":True}}):\n",
    "    doc_list.append({\n",
    "        'source':doc['Stitle'],\n",
    "        'dest':doc['Etitle'],\n",
    "        'google similarity': 1-doc['weight'],\n",
    "        'token similarity':doc['v1']['token'],\n",
    "        'STS similarity':1-doc['v1']['cosine'],\n",
    "    })\n",
    "len(doc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Counties_of_Iran',\n",
       " 'dest': 'Provinces_of_Iran',\n",
       " 'google similarity': 0.9995170648555507,\n",
       " 'token similarity': 0.5066223437499999,\n",
       " 'STS similarity': 0.610009006400506}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df_any = pd.DataFrame(doc_list)\n",
    "df_any.to_csv(\"../model/score_1m.csv\", index=False)\n",
    "df_any\n",
    "doc_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subject 30K 导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31231"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "DATABASE = pymongo.MongoClient(\"192.168.1.222\").temporary_token_similarity\n",
    "\n",
    "Collection = DATABASE.token_similarity_v20240729\n",
    "\n",
    "max_tree_struct = 0\n",
    "doc_list = []\n",
    "for doc in Collection.find({'v1':{\"$exists\":True}}):\n",
    "    doc_list.append({\n",
    "        'source':doc['STitle'],\n",
    "        'dest':doc['ETitle'],\n",
    "        'google similarity': 1-doc['weight'],\n",
    "        'token similarity':doc['v1']['token'],\n",
    "        'STS similarity':1-doc['v1']['cosine'],\n",
    "        'Tree similarity':1-doc['v1']['tree_edit_distance']/255,\n",
    "    })\n",
    "    # max_tree_struct = max(max_tree_struct, doc['v1'][''])\n",
    "len(doc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Geography',\n",
       " 'dest': 'Linguistics',\n",
       " 'google similarity': 0.5171631999999999,\n",
       " 'token similarity': 0.4790892138095238,\n",
       " 'STS similarity': 0.4055466218513175,\n",
       " 'Tree similarity': 0.8901960784313725}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_any = pd.DataFrame(doc_list)\n",
    "df_any.to_csv(\"../model/subject_lv2.csv\", index=False)\n",
    "df_any\n",
    "doc_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subject 200 \n",
    "处理 200 个 subject\n",
    "放入数据库,进行分布计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3968"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_list = ['Computer engineering', 'Computer science', 'Psychology', 'Mathematics', 'Environmental engineering', 'Chemical engineering', 'Theoretical computer science', 'Sociology', 'Economics', 'Biological engineering', 'Deep learning', 'Anthropology', 'Medicine', 'Philosophy', 'Blockchains', 'Electrical engineering', 'Engineering disciplines', 'Genetic engineering', 'Materials science', 'Physics', 'Logic', 'Cognitive science', 'Mechanical engineering', 'Geography', 'Chemistry', 'Industrial engineering', 'Theoretical physics', 'Linguistics', 'Machine learning', 'Biology', 'Environmental science', 'Civil engineering', 'Artificial intelligence', 'Genome editing', 'Political science', 'Quantum computing', 'Neuroscience', 'Geology', 'Literature', 'History']\n",
    "print(len(set(category_list)))\n",
    "\n",
    "import neo4j\n",
    "\n",
    "def query_title(title):\n",
    "    driver = neo4j.GraphDatabase.driver(\n",
    "            \"bolt://192.168.1.227:17688\",\n",
    "            auth=(\"neo4j\", \"neo4j-test\"),\n",
    "        )\n",
    "    record_list = []\n",
    "    with driver.session(database=\"enwiki\") as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (start:page {f_title: $source})-[r:page]->(end:page) \"\n",
    "            \"RETURN start.pageId as SID, end.f_title as title, end.pageId as EID \"\n",
    "            ,\n",
    "            source=title,\n",
    "        )\n",
    "        for record in result:\n",
    "            record_list.append(record)\n",
    "\n",
    "    return record_list\n",
    "\n",
    "title_set = set()\n",
    "for title in category_list:\n",
    "    for record in query_title(title):\n",
    "        title_set.add((title, int(record[\"SID\"])))\n",
    "        title_set.add((record[\"title\"], int(record[\"EID\"])))\n",
    "len(title_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "result_list = []\n",
    "\n",
    "title_data_list = list(title_set)\n",
    "\n",
    "tmp_list = []\n",
    "for title_b, ID_b in title_data_list:\n",
    "    if title_b in category_list:\n",
    "        tmp_list.append((title_b, ID_b))\n",
    "        \n",
    "for title_b, ID_b in title_data_list:\n",
    "    if title_b not in category_list:\n",
    "        tmp_list.append((title_b, ID_b))\n",
    "# tmp_list.extend(title_data_list[:162])\n",
    "# random.shuffle(tmp_list)\n",
    "print(len(tmp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(123131, 5043544, 0.8404469)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import psycopg\n",
    "\n",
    "\n",
    "def query_distance(list_set_1, list_set_2):\n",
    "    pg_uri = os.environ.get('postgres_uri')\n",
    "    ret = []\n",
    "    with psycopg.connect(pg_uri) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            for x in list_set_1:\n",
    "                greater_than_or_equal_x = list(item for item in list_set_2 if item > x)\n",
    "                if greater_than_or_equal_x:\n",
    "                    cursor.execute(\"SELECT source_id,target_id,weight FROM edges WHERE source_id = %s AND target_id = ANY(%s);\", \n",
    "                                (x, greater_than_or_equal_x,)\n",
    "                                ) \n",
    "                    for result in cursor:\n",
    "                        ret.append(result)\n",
    "            for x in list_set_2:\n",
    "                greater_than_or_equal_x = list(item for item in list_set_1 if item > x)\n",
    "                if greater_than_or_equal_x:\n",
    "                    cursor.execute(\"SELECT source_id,target_id,weight FROM edges WHERE source_id = %s AND target_id = ANY(%s);\", \n",
    "                                (x, greater_than_or_equal_x,)\n",
    "                                ) \n",
    "                    for result in cursor:\n",
    "                        ret.append(result)\n",
    "    return ret\n",
    "                    \n",
    "query_distance([123131,],[5043544])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19900it [1:13:11,  4.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31369"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "result_list = []\n",
    "sz = len(tmp_list)\n",
    "pbar = tqdm.tqdm()\n",
    "for i in range(sz-1):\n",
    "    for j in range(i+1, sz):\n",
    "        # print(j)\n",
    "        pbar.update(1)\n",
    "        x = tmp_list[i]\n",
    "        y = tmp_list[j]\n",
    "        if x[1] == y[1]:\n",
    "            continue\n",
    "        if x[1] < y[1]:\n",
    "            doc = {\n",
    "                \"SID\": x[1],\n",
    "                \"EID\": y[1],\n",
    "                \"STitle\": x[0],\n",
    "                \"ETitle\": y[0],\n",
    "            }\n",
    "        else:\n",
    "            doc = {\n",
    "                \"SID\": y[1],\n",
    "                \"EID\": x[1],\n",
    "                \"STitle\": y[0],\n",
    "                \"ETitle\": x[0],\n",
    "            }\n",
    "        ret = query_distance([doc['SID'],],[doc['EID'],])\n",
    "        if ret:\n",
    "            doc['weight'] = ret[0][2]\n",
    "            result_list.append(doc)\n",
    "    if i > 40:\n",
    "        break\n",
    "    # break\n",
    "len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# environment\n",
    "import pymongo\n",
    "import tqdm\n",
    "\n",
    "DATABASE = pymongo.MongoClient(\"192.168.1.222\").temporary_token_similarity\n",
    "\n",
    "Collection = DATABASE.token_similarity_v20240729\n",
    "\n",
    "document_list = []\n",
    "for doc in result_list:\n",
    "    doc['_id'] = f\"{doc['SID']}-{doc['EID']}\"\n",
    "    document_list.append(doc)\n",
    "try:\n",
    "    Collection.insert_many(document_list,ordered=False)\n",
    "except pymongo.errors.BulkWriteError as bwe:\n",
    "    print(bwe.details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test struct similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': 'success', 'data': {'a_b': 26}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "url = 'http://192.168.1.227:10004/wiki_api/api/tree/editDistance'\n",
    "\n",
    "# data = {\n",
    "#     \"stra\":\"[{'title':'a','edge':[[1,2],[1,33]]}]\",\n",
    "#     \"strb\":\"[{'title':'b','edge':[[1,2],[1,3],[2,4]]}]\",\n",
    "#     \"flag\":0\n",
    "# }\n",
    "data = {'stra': '[{\"title\": \"a\", \"edge\": [[267487, 9127632], [267487, 14924067], [267487, 25879157], [216180, 267487], [216180, 9127632], [216180, 14924067], [216180, 25879157], [37436, 60931], [37436, 72132], [37436, 106238], [37436, 163390], [37436, 216180], [37436, 267487], [37436, 9127632], [37436, 14924067], [37436, 25879157], [21245, 22921], [21245, 26781], [21245, 37080], [21245, 37436], [21245, 60931], [21245, 72132], [21245, 106238], [21245, 163390], [21245, 216180], [21245, 267487], [21245, 9127632], [21245, 14924067], [21245, 25879157], [60931, 72132], [60931, 106238], [60931, 163390], [60931, 216180], [60931, 267487], [60931, 9127632], [60931, 14924067], [60931, 25879157], [106238, 163390], [106238, 216180], [106238, 267487], [106238, 9127632], [106238, 14924067], [106238, 25879157], [9127632, 14924067], [9127632, 25879157], [4805, 5664], [4805, 21245], [4805, 22921], [4805, 26781], [4805, 37080], [4805, 37436], [4805, 60931], [4805, 72132], [4805, 106238], [4805, 163390], [4805, 216180], [4805, 267487], [4805, 9127632], [4805, 14924067], [4805, 25879157], [22921, 26781], [22921, 37080], [22921, 37436], [22921, 60931], [22921, 72132], [22921, 106238], [22921, 163390], [22921, 216180], [22921, 267487], [22921, 9127632], [22921, 14924067], [22921, 25879157], [5664, 19447], [5664, 21245], [5664, 22921], [5664, 26781], [5664, 37080], [5664, 37436], [5664, 60931], [5664, 72132], [5664, 106238], [5664, 163390], [5664, 216180], [5664, 267487], [5664, 9127632], [5664, 14924067], [5664, 25879157], [72132, 106238], [72132, 163390], [72132, 216180], [72132, 267487], [72132, 9127632], [72132, 14924067], [72132, 25879157], [3717, 4805], [3717, 5664], [3717, 19447], [3717, 21245], [3717, 22921], [3717, 26781], [3717, 37080], [3717, 37436], [3717, 60931], [3717, 72132], [3717, 106238], [3717, 163390], [3717, 216180], [3717, 267487], [3717, 9127632], [3717, 14924067], [3717, 25879157], [163390, 216180], [163390, 267487], [163390, 9127632], [163390, 25879157], [26781, 37080], [26781, 37436], [26781, 60931], [26781, 72132], [26781, 106238], [26781, 163390], [26781, 216180], [26781, 267487], [26781, 9127632], [26781, 14924067], [26781, 25879157], [26781, 37080], [26781, 37436], [26781, 60931], [26781, 72132], [26781, 106238], [26781, 163390], [26781, 216180], [26781, 267487], [26781, 9127632], [26781, 14924067], [26781, 25879157], [14924067, 25879157], [216180, 267487], [216180, 9127632], [216180, 14924067], [216180, 25879157], [19447, 21245], [19447, 22921], [19447, 26781], [19447, 37080], [19447, 37436], [19447, 106238], [19447, 9127632], [19447, 14924067], [37080, 37436], [37080, 60931], [37080, 72132], [37080, 106238], [37080, 163390], [37080, 216180], [37080, 267487], [37080, 9127632], [37080, 14924067], [37080, 25879157], [267487, 9127632], [267487, 14924067], [267487, 25879157], [216180, 267487], [216180, 9127632], [216180, 14924067], [216180, 25879157], [37436, 60931], [37436, 72132], [37436, 106238], [37436, 163390], [37436, 216180], [37436, 267487], [37436, 9127632], [37436, 14924067], [37436, 25879157], [21245, 22921], [21245, 26781], [21245, 37080], [21245, 37436], [21245, 60931], [21245, 72132], [21245, 106238], [21245, 163390], [21245, 216180], [21245, 267487], [21245, 9127632], [21245, 14924067], [21245, 25879157], [60931, 72132], [60931, 106238], [60931, 163390], [60931, 216180], [60931, 267487], [60931, 9127632], [60931, 14924067], [60931, 25879157], [106238, 163390], [106238, 216180], [106238, 267487], [106238, 9127632], [106238, 14924067], [106238, 25879157], [9127632, 14924067], [9127632, 25879157], [4805, 5664], [4805, 21245], [4805, 22921], [4805, 26781], [4805, 37080], [4805, 37436], [4805, 60931], [4805, 72132], [4805, 106238], [4805, 163390], [4805, 216180], [4805, 267487], [4805, 9127632], [4805, 14924067], [4805, 25879157], [22921, 26781], [22921, 37080], [22921, 37436], [22921, 60931], [22921, 72132], [22921, 106238], [22921, 163390], [22921, 216180], [22921, 267487], [22921, 9127632], [22921, 14924067], [22921, 25879157], [5664, 19447], [5664, 21245], [5664, 22921], [5664, 26781], [5664, 37080], [5664, 37436], [5664, 60931], [5664, 72132], [5664, 106238], [5664, 163390], [5664, 216180], [5664, 267487], [5664, 9127632], [5664, 14924067], [5664, 25879157], [72132, 106238], [72132, 163390], [72132, 216180], [72132, 267487], [72132, 9127632], [72132, 14924067], [72132, 25879157], [3717, 4805], [3717, 5664], [3717, 19447], [3717, 21245], [3717, 22921], [3717, 26781], [3717, 37080], [3717, 37436], [3717, 60931], [3717, 72132], [3717, 106238], [3717, 163390], [3717, 216180], [3717, 267487], [3717, 9127632], [3717, 14924067], [3717, 25879157], [163390, 216180], [163390, 267487], [163390, 9127632], [163390, 25879157], [26781, 37080], [26781, 37436], [26781, 60931], [26781, 72132], [26781, 106238], [26781, 163390], [26781, 216180], [26781, 267487], [26781, 9127632], [26781, 14924067], [26781, 25879157], [26781, 37080], [26781, 37436], [26781, 60931], [26781, 72132], [26781, 106238], [26781, 163390], [26781, 216180], [26781, 267487], [26781, 9127632], [26781, 14924067], [26781, 25879157], [14924067, 25879157], [216180, 267487], [216180, 9127632], ]}]', \n",
    "        'strb': '[{\"title\": \"b\", \"edge\": [[295691, 670497], [295691, 711728], [295691, 3741945], [8221, 34341], [8221, 47643], [8221, 185285], [8221, 295691], [8221, 711728], [8221, 3741945], [47643, 295691], [47643, 646121], [47643, 670497], [47643, 711728], [47643, 3741945], [711728, 3741945], [6978, 8221], [6978, 34341], [6978, 47643], [6978, 295691], [6978, 670497], [6978, 711728], [6978, 3741945], [34341, 34549], [34341, 34578], [34341, 670497], [34578, 47643], [34549, 34578], [34549, 47643], [295691, 670497], [295691, 711728], [295691, 3741945], [8221, 34341], [8221, 47643], [8221, 185285], [8221, 295691], [8221, 711728], [8221, 3741945], [47643, 295691], [47643, 646121], [47643, 670497], [47643, 711728], [47643, 3741945], [711728, 3741945], [6978, 8221], [6978, 34341], [6978, 47643], [6978, 295691], [6978, 670497], [6978, 711728],]}]', 'flag': 0}\n",
    "\n",
    "data = {'stra': '[{\"title\": \"a\", \"edge\": [[336271, 5912643], [336271, 208157], [5912643, 4063117], [18963754, 711288], [19005769, 2889], [20647050, 19555], [20647050, 20110874], [842224, 2396], [842224, 38393], [842224, 22122416], [6748280, 228108], [6748280, 208157], [22122416, 2889], [22122416, 711288], [605211, 2396], [711288, 228108], [208157, 9222], [2889, 15417], [5299, 13255], [5299, 27114], [5299, 19555], [6246, 19555], [6246, 15417], [6246, 19583], [19583, 23001]]}]', 'strb': '[{\"title\": \"b\", \"edge\": [[19653842, 26310], [19653842, 9236], [19653842, 13457], [19653842, 45086], [19653842, 9649], [71229276, 216186], [9236, 9127632], [9236, 646121], [9649, 18985062], [13457, 4250553], [38890, 9127632], [38890, 216186], [9127632, 17566205], [18985062, 4746766]]}]', 'flag': 0}\n",
    "\n",
    "# data = {'stra': '[{\"title\": \"a\", \"edge\": [[267487, 9127632], [267487, 14924067], [267487, 25879157], ]}]', \n",
    "#         'strb': '[{\"title\": \"b\", \"edge\": [[295691, 670497], [295691, 711728], [295691, 3741945], ]}]', \n",
    "#         'flag': 0}\n",
    "\n",
    "rep = session.post(url, json=data)\n",
    "rep.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小生成树的边：\n",
      "(1, 2)\n",
      "(2, 4)\n",
      "(3, 4)\n",
      "(4, 5)\n",
      "(5, 6)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "# 添加边来构建\n",
    "# 添加边和权重\n",
    "\n",
    "G = nx.Graph()\n",
    "edges_with_weight = [\n",
    "    (1, 2, 1), (1, 3, 3), (2, 4, 1), (21, 412, 10),\n",
    "    (3, 4, 2), (4, 5, 6), (5, 6, 1)\n",
    "]\n",
    "G.add_weighted_edges_from(edges_with_weight)\n",
    "\n",
    "# 找到所有连通分量\n",
    "connected_components = list(nx.connected_components(G))\n",
    "\n",
    "# 找到最大的连通分量\n",
    "max_component = max(connected_components, key=len)\n",
    "\n",
    "# 如果需要，可以创建一个新的图，只包含最大连通分量\n",
    "max_subgraph = G.subgraph(max_component)\n",
    "\n",
    "    \n",
    "# 计算最小生成树\n",
    "mst = nx.minimum_spanning_tree(max_subgraph)\n",
    "\n",
    "# 打印最小生成树的边\n",
    "print(\"最小生成树的边：\")\n",
    "for edge in mst.edges(data=False):\n",
    "    print(edge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
