{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import streamlit as st\n",
    "import tqdm\n",
    "from elasticsearch.helpers import scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5616951it [00:54, 103269.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5616951"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(st.secrets[\"elastic_uri\"])\n",
    "\n",
    "ret_doc = []\n",
    "# 指定索引名称\n",
    "index_name = \"wikipedia_title_20240201\"\n",
    "\n",
    "results = scan(\n",
    "    client=es,\n",
    "    query={\"query\": {\"match_all\": {}}},\n",
    "    index=index_name,\n",
    "    size=5_000,\n",
    "    scroll='5m'\n",
    ")\n",
    "\n",
    "# 遍历结果\n",
    "for doc in tqdm.tqdm(results):\n",
    "    # _source 包含了文档的原始数据\n",
    "    \n",
    "\n",
    "    my_doc = {\n",
    "        '_id': doc['_id'],\n",
    "        'title': [doc['_source']['title']]\n",
    "    }\n",
    "    if doc['_source']['redirect']:\n",
    "        my_doc['title'].extend(doc['_source']['redirect'])\n",
    "    ret_doc.append(my_doc)\n",
    "\n",
    "len(ret_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17836728it [06:56, 42867.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10533310\n",
      "6826307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # 更新 en_page 表的 title \n",
    "en_page_title = {}\n",
    "en_page_redirect = {}\n",
    "index_name = \"en_page\"\n",
    "\n",
    "results = scan(\n",
    "    client=es,\n",
    "    query={\"_source\": [\"title\", \"redirect\", \"id\"],\"query\": {\"match_all\": {}}},\n",
    "    index=index_name,\n",
    "    # size=10,\n",
    "    size=50_00,\n",
    "    scroll='5m'\n",
    "    # scroll='1s'\n",
    ")\n",
    "\n",
    "for doc in tqdm.tqdm(results):\n",
    "    # _source 包含了文档的原始数据\n",
    "    doc = doc['_source']\n",
    "    if 'redirect' in doc:\n",
    "        en_page_redirect[doc['title'].lower()] = doc['redirect'].lower()\n",
    "    else:\n",
    "        en_page_title[doc['title'].lower()] = doc['id']\n",
    "\n",
    "print(len(en_page_redirect))\n",
    "print(len(en_page_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试 wikititle 的 char 类型\n",
    "c_set  = set()\n",
    "for doc in ret_doc:\n",
    "    for title in doc['title'][:1]:\n",
    "        for c in title.lower():\n",
    "            c_set.add(c)\n",
    "len(c_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ƌ', '利', 'ử', 'ẫ', 'ǵ', 'ḑ', '̄', '英', '溫', '̣', 'ա', 'ộ', 'k', '淳', 'ᵵ', 'ơ', 'σ', 'η', '⋒', 'ʼ', '黎', 'ǝ', 'û', 'ĸ', ',', 'ĺ', '唯', 'æ', 'ȳ', '%', 'ằ', '⅓', 'ṯ', 'ú', '許', 'e', '†', '逯', '‒', '姞', 'u', 'ǽ', '松', 'ġ', '理', '栗', '瑞', '∴', 'ǹ', 'ʈ', 'ḱ', 'ƴ', 'о', 'θ', 'и', '̨', 'ȼ', '⁄', 'ǥ', 'с', '⋶', 'ặ', '͟', '吉', 'ƙ', '¥', '̩', '®', '严', 'b', 'y', '⋐', 'ũ', 'ỽ', 'ẋ', 'ợ', '우', '÷', '豫', 'ǔ', 'o', '@', 'φ', '⊷', '–', 'ớ', '̌', 'ɠ', 'ọ', 'ŝ', 'ʰ', '麟', '그', 'ḿ', '斯', 'ở', '阝', 'ȟ', '﹟', 'ݨ', '余', 'ḹ', 'ɗ', 'ấ', '嵇', '£', '^', 'ǃ', 'ș', 'я', 'ē', 'ṕ', 'ģ', 'g', '符', 'ĵ', 'ω', 'ṟ', 'ª', 'к', 'ḵ', '武', '諴', 'ƃ', 'ɪ', 'º', 'h', 'ç', '路', 'ų', 'ế', 'ẃ', 'ǧ', '•', '̃', '«', '¾', 'ề', '♭', '兰', 'ă', 'ƹ', '이', '9', '儀', 'c', '曲', '3', 'ǣ', 'ĉ', 'ↀ', '́', '李', 'ḩ', 'ō', '려', 'ǎ', '粟', '͎', '̂', '⟡', '计', '己', 'ᴋ', 'ố', 'ɛ', '·', 'a', 'ů', 'ğ', 'ñ', ':', 'ä', 'ņ', 'ь', '→', 'ǩ', 'ȥ', 'ݭ', '⊐', '∂', '낙', 'ứ', '禮', 'ṃ', '₂', 'ễ', '紅', 'ħ', 'ą', '上', 'ô', '帝', 'ŋ', '\\\\', 'ʻ', 'ꞥ', 'î', '盧', '⋓', '＜', '覃', 'ƭ', '7', '⋢', '³', '夜', '/', 'q', 'ḫ', '§', 'ẵ', 'ĥ', 'ꞌ', '伍', '+', 'ḻ', 'ί', 'ë', 'χ', '(', 'ḉ', '±', 'ű', 'κ', 'ɂ', '6', 'ɡ', 'ʊ', '~', 'ÿ', 'ỳ', 'ŏ', 'ś', '♯', '娄', '⊏', '堂', 'ḍ', 'е', 'ƒ', ' ', 'ʉ', 'n', '魯', '醇', '−', '̀', '던', 'ƶ', 'ổ', 'ã', 'ŷ', 'ĭ', 'œ', '⋇', '楼', 'з', '‑', '♪', '€', 'ℓ', 'è', 'δ', '̦', 'ķ', 'ƀ', 'ф', '竹', 'ï', '¹', 'ν', 'ĕ', '纪', '鹿', 'ừ', '″', 'ṝ', 'ċ', 'ę', 'н', '使', '照', 'ꞡ', '≂', 'ꞟ', 'č', 'ɔ', 'ắ', ')', '̤', 'ȧ', 'ṭ', 'ƈ', 'ồ', '厲', '元', '4', 'ƽ', 'ĝ', 'հ', 'ý', 'ı', 'ự', '⊓', 'ї', 'ị', 'ư', 'đ', 'ṛ', '★', '龍', '解', 'x', 'ـ', 'ĩ', '羊', '!', 'ş', 'ṇ', 'z', 'j', 'ù', 'ڄ', 'ó', '未', 'τ', '-', '∔', '리', 'ξ', 'd', 'ṅ', '蓟', 'ț', '√', ';', '5', 'ṁ', 'ệ', '₀', 'ṉ', '季', 'ạ', '闻', 'i', 'ε', 'ǂ', 'ď', 'ỵ', '裕', 'ł', '天', '̇', '×', 'µ', 'ỉ', 'ψ', 'ŭ', 'ì', 'ǐ', 'α', 'ӕ', '¡', 'ϕ', 'ī', '8', 'ꞧ', 'ầ', 'ʹ', '恂', '⊒', '⟨', '葉', '™', '⋯', '’', 'б', 'ń', '0', 'β', '°', 'ꞑ', 'ć', '?', 'μ', 'ɱ', 'ο', 'ў', 'ẩ', 'p', '⋑', 'ǒ', 'ť', '¢', 'ờ', 't', '⊑', 'å', 'ι', 'ꞩ', 'â', 'ỗ', '²', '循', 'ݙ', '顏', '—', 'ậ', 'ể', '駅', '愉', 'w', 'ð', 'ǁ', 'ḷ', 'ṣ', 'ẕ', 'ɓ', 'ř', 'ƨ', 'ň', 'λ', '章', 'ζ', '*', 'š', 'ɯ', 'ȓ', 'ż', 'ɣ', 's', '꞉', 'ụ', '九', 'ủ', '于', 'ƅ', 'ꝍ', 'ẻ', '怡', 'у', '애', 'ê', 'ě', '蘆', 'р', '͘', 'ẹ', '̧', 'á', 'ɲ', 'ā', 'f', 'ڼ', '文', '食', 'ß', '원', 'ά', 'ő', 'л', '陸', 'ỹ', 'ʔ', 'ỷ', 'ʾ', 'ǫ', '蓝', 'l', '純', '⟩', '′', '№', 'յ', 'm', '=', 'д', '$', '汲', '⁺', 'ẽ', 'ṡ', 'ǯ', '姜', 'ŵ', 'ḥ', 'ḳ', '陽', '項', '阎', 'ŕ', 'ɵ', '̓', 'ʿ', 'ỡ', 'ỏ', '韋', '﹥', '.', '↔', 'ẁ', '冀', 'ź', '暨', '̈', 'ø', 'ž', '道', 'ⱺ', '⊺', '»', '瞿', 'v', '가', '´', '直', 'õ', 'r', '酈', '̍', 'ȋ', 'а', '姒', 'ţ', 'é', '齊', '深', '時', '영', 'ḏ', 'υ', 'γ', '莉', 'ả', '古', '徐', 'ū', 'ẓ', 'ö', 'г', '왔', 'қ', 'ľ', 'ǀ', '籍', 'ʋ', 'ļ', '¼', '麒', '1', '½', 'ɨ', '穎', '⊶', 'ƥ', '̱', 'ė', 'ə', 'þ', '2', 'í', 'м', '≠', 'ü', 'à', 'ữ', '¿', '‡', '›', \"'\", 'ύ', '屈', '江', 'ṳ', 'ẑ', '♡', '⁵', '⋣', '∞', 'ʽ', '⅔', '・', '‐', '…', '刀', 'ò', 'π', 'į'}\n"
     ]
    }
   ],
   "source": [
    "print(c_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 字典树的方案失败了,太占内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    __slots__ = ['children', 'ID']\n",
    "    def __init__(self):\n",
    "        self.children = {}  # 子节点，使用字典存储\n",
    "        self.ID = 0  # 标记是否为单词的结尾\n",
    "\n",
    "class WikipediaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "        \n",
    "    def insert(self, token_list, ID):\n",
    "        node = self.root\n",
    "        for token in token_list:\n",
    "            # 如果字符不在当前节点的子节点中，添加一个新节点\n",
    "            if token not in node.children:\n",
    "                node.children[token] = TrieNode()\n",
    "            # 移动到子节点\n",
    "            node = node.children[token]\n",
    "        # 设置当前节点为单词的结尾\n",
    "        node.ID = ID\n",
    "\n",
    "    def search(self, token_list):\n",
    "        \"\"\"\n",
    "        -1 表示不存在该单词\n",
    "        0 表示存在该单词，但是不是单词的结尾\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        for token in token_list:\n",
    "            # 如果字符不在当前节点的子节点中，表示单词不存在\n",
    "            if token not in node.children:\n",
    "                return -1\n",
    "            node = node.children[token]\n",
    "        # 检查当前节点是否为单词的结尾\n",
    "        return node.ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# WT = WikipediaTokenizer()\n",
    "\n",
    "# for doc in tqdm.tqdm(ret_doc):\n",
    "#     ID = doc['_id']\n",
    "#     for title in doc['title'][:1]:\n",
    "#         WT.insert(title.lower(), ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('../model/WT.pkl', 'wb') as f:\n",
    "#     train_data = pickle.dump(WT,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('../model/WT.pkl', 'rb') as f:\n",
    "#     WT = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 dict 方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5616951/5616951 [00:09<00:00, 570984.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14621981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6826307/6826307 [00:04<00:00, 1619875.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15848253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10533310/10533310 [00:10<00:00, 1051817.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16878172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "WTD = {}\n",
    "for doc in tqdm.tqdm(ret_doc):\n",
    "    ID = int(doc['_id'])\n",
    "    for title in doc['title'][:]:\n",
    "        WTD[title.lower()] = ID\n",
    "        \n",
    "\n",
    "# print(len(en_page_title))\n",
    "print(len(WTD))\n",
    "\n",
    "for title,ID in tqdm.tqdm(en_page_title.items()):\n",
    "    WTD[title] = int(ID)\n",
    "    \n",
    "print(len(WTD))\n",
    "for title,true_title in tqdm.tqdm(en_page_redirect.items()):\n",
    "    if true_title in WTD:\n",
    "         WTD[title] = WTD[true_title]\n",
    "         \n",
    "\n",
    "print(len(WTD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"\"\"\n",
    "The Facebookmoord (\"Facebook murder\") is a term Harvard University coined by Dutch media for the 2012 murder of Joyce (Winsie) Hau, by the then 14–year-old Jinhua K. from Capelle aan den IJssel, in the Netherlands. Hau's father was also injured during the attack. The case was given its name because the motive lay in a disagreement on Facebook.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "\n",
    "with gzip.open('../model/WTD.pkl.gz', 'wb') as f:\n",
    "    train_data = pickle.dump(WTD,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "\n",
    "with gzip.open('../model/WTD.pkl.gz', 'rb') as f:\n",
    "    WTD = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(290, 'a'),\n",
       "  (20171, 'murder'),\n",
       "  (21673, 'name'),\n",
       "  (47374, '2012'),\n",
       "  (83427, 'father'),\n",
       "  (180184, 'term'),\n",
       "  (216834, 'disagreement'),\n",
       "  (224192, 'in'),\n",
       "  (294441, 'is a'),\n",
       "  (299083, 'the motive'),\n",
       "  (310121, 'its'),\n",
       "  (360668, 'by'),\n",
       "  (436179, 'of'),\n",
       "  (788093, 'injured'),\n",
       "  (904370, 'because'),\n",
       "  (920255, 'aan'),\n",
       "  (1715111, 'was'),\n",
       "  (2017600, 'den'),\n",
       "  (2102103, 'on'),\n",
       "  (2558477, 'given'),\n",
       "  (2853114, 'jinhua'),\n",
       "  (3475505, 'for'),\n",
       "  (3835872, 'coined'),\n",
       "  (4140811, 'lay'),\n",
       "  (6133489, 'k.'),\n",
       "  (7529378, 'facebook.'),\n",
       "  (8282451, 'dutch media'),\n",
       "  (9716090, 'the'),\n",
       "  (10144925, 'capelle'),\n",
       "  (16633798, 'the case'),\n",
       "  (18426501, 'harvard university'),\n",
       "  (18534749, 'also'),\n",
       "  (20965144, 'joyce'),\n",
       "  (23139855, 'from'),\n",
       "  (27399125, 'the then'),\n",
       "  (76215005, 'during')},\n",
       " [('the', 9716090),\n",
       "  'facebookmoord (\"facebook murder\")',\n",
       "  ('is a', 294441),\n",
       "  ('term', 180184),\n",
       "  ('harvard university', 18426501),\n",
       "  ('coined', 3835872),\n",
       "  ('by', 360668),\n",
       "  ('dutch media', 8282451),\n",
       "  ('for', 3475505),\n",
       "  ('the', 9716090),\n",
       "  ('2012', 47374),\n",
       "  ('murder', 20171),\n",
       "  ('of', 436179),\n",
       "  ('joyce', 20965144),\n",
       "  '(winsie) hau,',\n",
       "  ('by', 360668),\n",
       "  ('the then', 27399125),\n",
       "  '14–year-old',\n",
       "  ('jinhua', 2853114),\n",
       "  ('k.', 6133489),\n",
       "  ('from', 23139855),\n",
       "  ('capelle', 10144925),\n",
       "  ('aan', 920255),\n",
       "  ('den', 2017600),\n",
       "  'ijssel,',\n",
       "  ('in', 224192),\n",
       "  ('the', 9716090),\n",
       "  \"netherlands. hau's\",\n",
       "  ('father', 83427),\n",
       "  ('was', 1715111),\n",
       "  ('also', 18534749),\n",
       "  ('injured', 788093),\n",
       "  ('during', 76215005),\n",
       "  ('the', 9716090),\n",
       "  'attack.',\n",
       "  ('the case', 16633798),\n",
       "  ('was', 1715111),\n",
       "  ('given', 2558477),\n",
       "  ('its', 310121),\n",
       "  ('name', 21673),\n",
       "  ('because', 904370),\n",
       "  ('the motive', 299083),\n",
       "  ('lay', 4140811),\n",
       "  ('in', 224192),\n",
       "  ('a', 290),\n",
       "  ('disagreement', 216834),\n",
       "  ('on', 2102103),\n",
       "  ('facebook.', 7529378)])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_text(text):\n",
    "    return text.lower().split(\" \")\n",
    "\n",
    "\n",
    "def get_token(text):\n",
    "    token_set = set()\n",
    "    annotated_text = []\n",
    "    \n",
    "    token_list = format_text(text)\n",
    "    token_range = 5\n",
    "    start_token_index = 0\n",
    "    end_token_index = token_range\n",
    "    last_token_index = 0\n",
    "    \n",
    "    while start_token_index < len(token_list):\n",
    "        \n",
    "        sub_token_list = token_list[start_token_index:end_token_index]\n",
    "        sub_text = \" \".join(sub_token_list).strip()\n",
    "        ID = WTD.get(sub_text)\n",
    "        \n",
    "        if ID:\n",
    "            # 前置空白区\n",
    "            last_string = \" \".join(token_list[last_token_index:start_token_index])\n",
    "            if last_string:\n",
    "                annotated_text.append(last_string)\n",
    "                \n",
    "            # 当前 token 区\n",
    "            annotated_text.append((sub_text, ID))\n",
    "            last_token_index = end_token_index\n",
    "            start_token_index = end_token_index\n",
    "            end_token_index = start_token_index + token_range\n",
    "            \n",
    "            token_set.add((ID, sub_text))\n",
    "        else:\n",
    "            if end_token_index - start_token_index > 1: \n",
    "                end_token_index -= 1\n",
    "            else:\n",
    "                start_token_index += 1\n",
    "                end_token_index = start_token_index + token_range\n",
    "            \n",
    "        \n",
    "    return token_set, annotated_text\n",
    "\n",
    "\n",
    "get_token(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.3.1%2Bcpu-cp312-cp312-linux_x86_64.whl (190.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.4/190.4 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.18.1%2Bcpu-cp312-cp312-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.3.1%2Bcpu-cp312-cp312-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.3.1+cpu torchaudio-2.3.1+cpu torchvision-0.18.1+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelscope in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (1.16.0)\n",
      "Requirement already satisfied: addict in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: simplejson in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (3.19.2)\n",
      "Requirement already satisfied: sortedcontainers in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (4.42.3)\n",
      "Requirement already satisfied: sentence_transformers in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: requests>=2.25 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from modelscope) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from modelscope) (4.66.4)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from modelscope) (2.2.2)\n",
      "Requirement already satisfied: filelock in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from sentence_transformers) (2.3.1+cpu)\n",
      "Requirement already satisfied: scikit-learn in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: Pillow in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from requests>=2.25->modelscope) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from requests>=2.25->modelscope) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from requests>=2.25->modelscope) (2024.6.2)\n",
      "Requirement already satisfied: sympy in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install modelscope addict simplejson sortedcontainers transformers sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ider/miniconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import modelscope\n",
    "import os\n",
    "# os.environ['http_proxy'] = 'http://192.168.1.227:23333'\n",
    "# os.environ['https_proxy'] = 'http://192.168.1.227:23333'\n",
    "os.environ['http_proxy'] = ''\n",
    "os.environ['https_proxy'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399813\n",
      "0.7471952\n"
     ]
    }
   ],
   "source": [
    "# from modelscope.models import Model\n",
    "from transformers import AutoModel\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cache_dir=\"/home/ider/.cache/modelscope/hub/jinaai/jina-embeddings-v2-small-en\"\n",
    "cos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n",
    "# model = Model.from_pretrained('jinaai/jina-embeddings-v2-small-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "model = AutoModel.from_pretrained(cache_dir, trust_remote_code=True)\n",
    "embeddings = model.encode(['How is the weather today?', 'What is the current weather like today?'])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))\n",
    "\n",
    "embeddings = model.encode(['How is the weather today?', '今天天气怎么样?'])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7860607\n",
      "0.8722507\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModel\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n",
    "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "embeddings = model.encode(['How is the weather today?', '今天天气怎么样?'])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))\n",
    "\n",
    "\n",
    "embeddings = model.encode(['How is the weather today?', 'What is the current weather like today?'])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39379686\n",
      "0.125564\n",
      "0.42542523\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(['How is the weather today?', '今天出发?'])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))\n",
    "\n",
    "embeddings = model.encode(['How is the weather today?', 'nice! fake news lets go to school'])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))\n",
    "\n",
    "\n",
    "embeddings = model.encode(['How is the weather today?', 'weather is nice '])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找 1000 个例子测试\n",
    "我们就用3级学科进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_list = ['Computer engineering', 'Computer science', 'Psychology', 'Mathematics', 'Environmental engineering', 'Chemical engineering', 'Theoretical computer science', 'Sociology', 'Economics', 'Biological engineering', 'Deep learning', 'Anthropology', 'Medicine', 'Philosophy', 'Blockchains', 'Electrical engineering', 'Engineering disciplines', 'Genetic engineering', 'Materials science', 'Physics', 'Logic', 'Cognitive science', 'Mechanical engineering', 'Geography', 'Chemistry', 'Industrial engineering', 'Theoretical physics', 'Linguistics', 'Machine learning', 'Biology', 'Environmental science', 'Civil engineering', 'Artificial intelligence', 'Genome editing', 'Political science', 'Quantum computing', 'Neuroscience', 'Geology', 'Literature', 'History']\n",
    "len(set(category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3968"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import neo4j\n",
    "\n",
    "def query_title(title):\n",
    "    driver = neo4j.GraphDatabase.driver(\n",
    "            \"bolt://192.168.1.227:17688\",\n",
    "            auth=(\"neo4j\", \"neo4j-test\"),\n",
    "        )\n",
    "    record_list = []\n",
    "    with driver.session(database=\"enwiki\") as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (start:page {f_title: $source})-[r:page]->(end:page) \"\n",
    "            \"RETURN start.pageId as SID, end.f_title as title, end.pageId as EID \"\n",
    "            ,\n",
    "            source=title,\n",
    "        )\n",
    "        for record in result:\n",
    "            record_list.append(record)\n",
    "\n",
    "    return record_list\n",
    "\n",
    "title_set = set()\n",
    "for title in category_list:\n",
    "    for record in query_title(title):\n",
    "        title_set.add((title, int(record[\"SID\"])))\n",
    "        title_set.add((record[\"title\"], int(record[\"EID\"])))\n",
    "len(title_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ider/miniconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-09 20:02:52.525 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/ider/miniconda3/envs/py312/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-07-09 20:03:14.578 No runtime found, using MemoryCacheStorageManager\n",
      "2024-07-09 20:03:21.165 No runtime found, using MemoryCacheStorageManager\n",
      "2024-07-09 20:03:21.166 No runtime found, using MemoryCacheStorageManager\n",
      "2024-07-09 20:03:21.167 No runtime found, using MemoryCacheStorageManager\n",
      "2024-07-09 20:03:21.168 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tqdm\n",
    "\n",
    "# 使用相对路径添加父目录到搜索路径\n",
    "sys.path.append(\"../gpc_demo\") \n",
    "sys.path.append(\"..\") \n",
    "\n",
    "from utils import calculate_cartesian_product_distances, get_token, search_wikipedia, get_plaintext, calculate_similarity,query_partner_distancles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [5:17:04<00:00, 137.86s/it]  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "result_list = []\n",
    "\n",
    "title_data_list = list(title_set)\n",
    "\n",
    "tmp_list = []\n",
    "for title_b, ID_b in title_data_list:\n",
    "    if title_b in category_list:\n",
    "        tmp_list.append((title_b, ID_b))\n",
    "tmp_list.extend(title_data_list[:100])\n",
    "random.shuffle(tmp_list)\n",
    "print(len(tmp_list))\n",
    "\n",
    "for title_a, ID_a in tqdm.tqdm(tmp_list):\n",
    "    for title_b, ID_b in tmp_list:\n",
    "        if title_a == title_b:\n",
    "            continue\n",
    "        \n",
    "        plaintext_a = get_plaintext(ID_a)\n",
    "        plaintext_b = get_plaintext(ID_b)\n",
    "        \n",
    "        if not plaintext_a or not plaintext_b:\n",
    "            continue\n",
    "        \n",
    "        token_set_1, _ = get_token(plaintext_a)\n",
    "        token_set_2, _ = get_token(plaintext_b)\n",
    "        \n",
    "        df, _ = calculate_cartesian_product_distances(\n",
    "                    tuple(token_set_1 - token_set_2), \n",
    "                    tuple(token_set_2 - token_set_1),\n",
    "                    tuple(token_set_2 & token_set_1),\n",
    "                )\n",
    "        if len(df):\n",
    "            result_list.append({\n",
    "                \"source\": title_a,\n",
    "                \"dest\": title_b,\n",
    "                \"title distance\": query_partner_distancles(ID_a, ID_b),\n",
    "                \"tokens distance\": df['distance'].mean().round(4),\n",
    "                \"STS\": calculate_similarity(plaintext_a, plaintext_b)\n",
    "            })\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ok = pd.DataFrame(result_list)\n",
    "df_ok.to_csv(\"./tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>dest</th>\n",
       "      <th>title distance</th>\n",
       "      <th>tokens distance</th>\n",
       "      <th>STS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Thin film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>-0.018466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Neoevolutionism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.109186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Biological motion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.082935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Field (mineral deposit)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>-0.017856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Stereochemistry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.112445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18727</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Dry well</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.180327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18728</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Chemical stability</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5863</td>\n",
       "      <td>0.086699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18729</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Biology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.036248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18730</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Digital empathy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6314</td>\n",
       "      <td>0.009882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18731</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Hybrid intelligent system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>0.237502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18732 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source                       dest  title distance  \\\n",
       "0      Crosslinguistic influence                  Thin film             NaN   \n",
       "1      Crosslinguistic influence            Neoevolutionism             NaN   \n",
       "2      Crosslinguistic influence          Biological motion             NaN   \n",
       "3      Crosslinguistic influence    Field (mineral deposit)             NaN   \n",
       "4      Crosslinguistic influence            Stereochemistry             NaN   \n",
       "...                          ...                        ...             ...   \n",
       "18727              River linking                   Dry well             NaN   \n",
       "18728              River linking         Chemical stability             NaN   \n",
       "18729              River linking                    Biology             NaN   \n",
       "18730              River linking            Digital empathy             NaN   \n",
       "18731              River linking  Hybrid intelligent system             NaN   \n",
       "\n",
       "       tokens distance       STS  \n",
       "0               0.5112 -0.018466  \n",
       "1               0.4714  0.109186  \n",
       "2               0.4410  0.082935  \n",
       "3               0.6099 -0.017856  \n",
       "4               0.4835  0.112445  \n",
       "...                ...       ...  \n",
       "18727           0.5708  0.180327  \n",
       "18728           0.5863  0.086699  \n",
       "18729           0.6240  0.036248  \n",
       "18730           0.6314  0.009882  \n",
       "18731           0.6868  0.237502  \n",
       "\n",
       "[18732 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ok[df_ok['STS'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics.pairwise import (\n",
    "    paired_cosine_distances,\n",
    "    paired_euclidean_distances,\n",
    "    paired_manhattan_distances,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>dest</th>\n",
       "      <th>google similarity</th>\n",
       "      <th>token similarity</th>\n",
       "      <th>STS similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Thin film</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>-0.018466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Neoevolutionism</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.109186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Biological motion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.082935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Field (mineral deposit)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3901</td>\n",
       "      <td>-0.017856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crosslinguistic influence</td>\n",
       "      <td>Stereochemistry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5165</td>\n",
       "      <td>0.112445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18727</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Dry well</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4292</td>\n",
       "      <td>0.180327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18728</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Chemical stability</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4137</td>\n",
       "      <td>0.086699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18729</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Biology</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.036248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18730</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Digital empathy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.009882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18731</th>\n",
       "      <td>River linking</td>\n",
       "      <td>Hybrid intelligent system</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.237502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18732 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source                       dest  \\\n",
       "0      Crosslinguistic influence                  Thin film   \n",
       "1      Crosslinguistic influence            Neoevolutionism   \n",
       "2      Crosslinguistic influence          Biological motion   \n",
       "3      Crosslinguistic influence    Field (mineral deposit)   \n",
       "4      Crosslinguistic influence            Stereochemistry   \n",
       "...                          ...                        ...   \n",
       "18727              River linking                   Dry well   \n",
       "18728              River linking         Chemical stability   \n",
       "18729              River linking                    Biology   \n",
       "18730              River linking            Digital empathy   \n",
       "18731              River linking  Hybrid intelligent system   \n",
       "\n",
       "       google similarity  token similarity  STS similarity  \n",
       "0                    0.0            0.4888       -0.018466  \n",
       "1                    0.0            0.5286        0.109186  \n",
       "2                    0.0            0.5590        0.082935  \n",
       "3                    0.0            0.3901       -0.017856  \n",
       "4                    0.0            0.5165        0.112445  \n",
       "...                  ...               ...             ...  \n",
       "18727                0.0            0.4292        0.180327  \n",
       "18728                0.0            0.4137        0.086699  \n",
       "18729                0.0            0.3760        0.036248  \n",
       "18730                0.0            0.3686        0.009882  \n",
       "18731                0.0            0.3132        0.237502  \n",
       "\n",
       "[18732 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "except_row = ['Field (mineral deposit)',\n",
    " 'Electromaterials',\n",
    " 'Inverter-based resource',\n",
    " 'Transparent heating film',\n",
    " 'Epistemic cognition',\n",
    " 'Bullwheel',\n",
    " 'Policy monitoring',\n",
    " 'Transparent wood composite',\n",
    " 'Ferroelasticity',\n",
    " 'Direct laser interference patterning',\n",
    " 'COMOS',\n",
    " 'Photomechanical effect',\n",
    " 'Cerebral rubicon',\n",
    " 'Testing of advanced thermoplastic composite welds',\n",
    " 'Ore dock',\n",
    " 'Bioresilience',\n",
    " 'The Fable of Oscar',\n",
    " 'Survey camp',\n",
    " 'Reverse roll coating',\n",
    " 'Mental timeline',\n",
    " 'River linking']\n",
    "df_any = df_ok.fillna(1, inplace=False)\n",
    "df_any = df_any.rename(columns={'title distance': 'google similarity', \n",
    "                                'tokens distance': 'token similarity',\n",
    "                                'STS': 'STS similarity',\n",
    "                                })\n",
    "# df_any = df_any[~df_any['source'].isin(except_row)]\n",
    "df_any['google similarity'] = 1 - df_any['google similarity']\n",
    "df_any['token similarity'] = 1 - df_any['token similarity']\n",
    "df_any.to_csv(\"../model/score_subject.csv\", index=False)\n",
    "df_any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15873"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = [1,2,3]\n",
    "# b = [4,-1,8]\n",
    "# print(pearsonr(a,b))\n",
    "# print(spearmanr(a,b))\n",
    "len(df_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.37640778945453646, pvalue=0.0)\n",
      "SignificanceResult(statistic=0.3153197108388149, pvalue=0.0)\n",
      "SignificanceResult(statistic=0.462048788927142, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# \t\tSTS\n",
    "# df_ok[df_ok['STS'] > 0.5]\n",
    "a = df_any['STS']\n",
    "b = df_any['tokens distance']\n",
    "# print(pearsonr(a,b))\n",
    "print(spearmanr(a,b))\n",
    "\n",
    "a = df_any['title distance']\n",
    "b = df_any['tokens distance']\n",
    "# print(pearsonr(a,b))\n",
    "print(spearmanr(a,b))\n",
    "\n",
    "\n",
    "a = df_any['STS']\n",
    "b = df_any['title distance']\n",
    "# print(pearsonr(a,b))\n",
    "print(spearmanr(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_any[df_any['source'] == \"Ferroelasticity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25608762919702605\n",
      "0.271908759676496\n",
      "0.21887605805293883\n",
      "0.18574890528335267\n",
      "0.23369066817574438\n",
      "0.25623069393453884\n",
      "0.43343848957457887\n",
      "0.3090280699762393\n",
      "0.23636565663660966\n",
      "0.48319851915246287\n",
      "0.2772394168617563\n",
      "0.20556582063818993\n",
      "0.34491288502009\n",
      "0.2121037478804271\n",
      "0.48080836659021353\n",
      "0.5145502043685085\n",
      "0.45563694662478144\n",
      "0.5573218755711219\n",
      "0.4509163800354335\n",
      "0.4632086806306368\n",
      "0.7090190844030354\n",
      "0.40989279730876194\n",
      "0.20317020185395815\n",
      "0.18468094142212796\n",
      "0.6292255709175253\n",
      "0.620223432976125\n",
      "0.7047140594641933\n",
      "0.4049339366786404\n",
      "0.14783457167642364\n",
      "-0.021725520967776347\n",
      "0.13334637353717774\n",
      "-0.09755739784181279\n",
      "0.049326362366699\n",
      "0.4783948960874043\n",
      "0.38348024517355994\n",
      "0.3084022308382367\n",
      "0.5228213831123807\n",
      "0.19692480223823558\n",
      "0.20462944841432473\n",
      "0.3913308792345814\n",
      "0.3273263442070751\n",
      "0.40960022793393236\n",
      "0.40274035671325864\n",
      "0.32998473735951617\n",
      "0.7034808764702121\n",
      "0.5429667856413554\n",
      "0.47186457231304996\n",
      "0.7284986097305473\n",
      "0.316456375596099\n",
      "0.013009675442184346\n",
      "-0.056374865588637135\n",
      "0.21273874946095003\n",
      "0.33462235390555445\n",
      "0.264678742289784\n",
      "0.34002396540043484\n",
      "0.43288471668385947\n",
      "0.47075728420284907\n",
      "0.22339185890078678\n",
      "0.1667345315996887\n",
      "-0.09232488373352034\n",
      "0.4705992166353827\n",
      "0.4488395361217839\n",
      "0.437089036079575\n",
      "0.2888544862133259\n",
      "0.04891983720771486\n",
      "0.06854007167875098\n",
      "0.2734717342162544\n",
      "0.36148661272218563\n",
      "0.33078552695515956\n",
      "0.28178690059957073\n",
      "0.3158524561068474\n",
      "0.2622566370703\n",
      "0.5044595042792038\n",
      "0.4960929922261338\n",
      "0.7041942291125586\n",
      "0.25087362511852623\n",
      "0.14371506745194293\n",
      "0.02947097929529729\n",
      "0.34830607024419646\n",
      "0.4227164271119993\n",
      "0.747603993278364\n",
      "0.3070168376620237\n",
      "0.2794408158078847\n",
      "0.21708540269114548\n",
      "0.5298705326088483\n",
      "0.48980653096784305\n",
      "0.7100285678948008\n",
      "0.269526926465458\n",
      "0.48028364094705595\n",
      "0.5352385456441762\n",
      "0.43530268310573156\n",
      "0.44118805887536994\n",
      "0.7378172295683487\n",
      "0.4454881904851284\n",
      "0.4615540541742615\n",
      "0.6170678735678854\n",
      "0.07535467865860017\n",
      "0.06686502328933473\n",
      "-0.03178810019187269\n",
      "0.05358780683615778\n",
      "0.053432278874421105\n",
      "0.14431984189027577\n",
      "0.5544837160848725\n",
      "0.243280260029891\n",
      "0.26797393647792833\n",
      "0.33793157736932145\n",
      "0.23375845924506444\n",
      "0.6244828065266238\n",
      "0.33699970480996205\n",
      "0.0737212361235584\n",
      "0.1474419561548971\n",
      "0.4925624424668098\n",
      "0.38605501515568336\n",
      "0.28961482700917673\n",
      "0.42181018423519995\n",
      "0.16244543291766775\n",
      "0.1463554808619242\n",
      "0.22783372851615852\n",
      "0.13263374046300752\n",
      "0.09317201780376479\n",
      "0.14004952101702367\n",
      "0.045217217395878626\n",
      "0.10051358839296266\n",
      "0.19341034189040712\n",
      "0.1282493069647896\n",
      "0.12605625938156415\n",
      "0.2157673082345745\n",
      "-0.07124995490207724\n",
      "0.05371092791040559\n",
      "0.401502799866401\n",
      "0.3638435310176434\n",
      "0.7146185550303944\n",
      "0.3243460830400598\n",
      "0.08333458807884761\n",
      "0.10529840898790321\n",
      "0.2648726857141174\n",
      "0.16623392387989702\n",
      "0.31507993670787277\n",
      "0.054310515506369644\n",
      "0.1830515547191868\n",
      "0.020519340801658126\n",
      "0.2008453835497478\n",
      "0.24231336104087478\n",
      "0.17878750866330634\n",
      "0.48783697854182034\n",
      "0.42388293259130383\n",
      "0.6545685158110843\n",
      "0.34507381606288723\n",
      "0.38245174473235416\n",
      "0.5284473891098419\n",
      "0.1361463486793256\n",
      "0.08659558261634374\n",
      "0.13701767324083056\n",
      "0.5758292821461558\n",
      "0.49841896458696777\n",
      "0.7688647683796435\n",
      "0.520147656058913\n",
      "0.40885125298999514\n",
      "0.5775414887060093\n",
      "0.39580838609479624\n",
      "0.1568642909701321\n",
      "-0.03164287971874188\n",
      "0.15102220832838048\n",
      "0.2900789253997916\n",
      "0.15837329331757494\n",
      "0.5386997125963116\n",
      "0.5284954044763062\n",
      "0.7049391799972017\n",
      "0.3420737823505395\n",
      "0.2957446318571867\n",
      "0.4349824663774674\n",
      "0.42362382404896975\n",
      "0.39124144039566067\n",
      "0.62732672307505\n",
      "0.4111566800788192\n",
      "0.3631856989898118\n",
      "0.7398458536474697\n",
      "0.37166060181265226\n",
      "0.18787154980458765\n",
      "0.3032659144006536\n",
      "0.4806555380232936\n",
      "0.3914835749692446\n",
      "0.6599382357224898\n",
      "0.3373151255246358\n",
      "0.16968824464012813\n",
      "0.0471509095239312\n",
      "0.366057755157809\n",
      "0.24140800123798467\n",
      "0.18957769526124968\n",
      "0.1809609570243345\n",
      "0.1293861422439379\n",
      "-0.008756951897824293\n",
      "0.18914295982336524\n",
      "0.2247985749173102\n",
      "0.18227929695426742\n",
      "0.5664464943122067\n",
      "0.5945733294874548\n",
      "0.6343362014884502\n",
      "0.364275866021349\n",
      "0.35863903503977373\n",
      "0.162531354157831\n",
      "0.4769321047008099\n",
      "0.3711909991868788\n",
      "0.6997825752456622\n",
      "0.21742032137710127\n",
      "0.17560608888681897\n",
      "0.08543262622896883\n",
      "0.48916432302423524\n",
      "0.37307183315511827\n",
      "0.48928124233408843\n",
      "0.17091843732972523\n",
      "0.08659568589930236\n",
      "0.0295958174200194\n",
      "0.37846702488045286\n",
      "0.11576717098160642\n",
      "-0.028898718254135366\n",
      "0.029668694907443546\n",
      "0.10190924320279134\n",
      "0.09757188274956427\n",
      "0.469859893797363\n",
      "0.3035085153298937\n",
      "0.4793500371110248\n",
      "0.5178772279502138\n",
      "0.5463231439275953\n",
      "0.7229495430027457\n",
      "0.2826449435455024\n",
      "0.27560646200652394\n",
      "0.5955725993483366\n",
      "0.6731679087047078\n",
      "0.6016584564266612\n",
      "0.7384466550263744\n",
      "0.2057199662126228\n",
      "0.19548729506116141\n",
      "0.1512312489543566\n",
      "0.4959346975415705\n",
      "0.43048684146844024\n",
      "0.5836863068411838\n",
      "0.13143415976236617\n",
      "0.15294584058235705\n",
      "0.053876268024546585\n",
      "0.032555290439967355\n",
      "0.014093831506769015\n",
      "0.03035569685542\n",
      "0.3163759277277105\n",
      "0.10940057311804999\n",
      "-0.13176987354017944\n",
      "0.6209372417079481\n",
      "0.49525653661447827\n",
      "0.7427496102839735\n",
      "0.42157805226612294\n",
      "0.37247148326728086\n",
      "0.7511653873494613\n",
      "0.33805084705717015\n",
      "0.35548473842654277\n",
      "0.7645221906337015\n",
      "0.19817445163273734\n",
      "0.2854339355353983\n",
      "0.025310249437821883\n",
      "0.596046916051587\n",
      "0.4276906255116949\n",
      "0.5283795479468447\n",
      "0.4924626750789863\n",
      "0.34099743375826613\n",
      "0.587610153760855\n",
      "0.49556623811825484\n",
      "0.5052195895521904\n",
      "0.6515654605015844\n",
      "0.2818846134597542\n",
      "0.12109296799022748\n",
      "0.40181218975675886\n",
      "0.5461936420432861\n",
      "0.5959982940427838\n",
      "0.761321241184312\n",
      "0.12210592102577308\n",
      "0.17743165464322963\n",
      "-0.0008465974468749077\n",
      "0.3102331250959053\n",
      "0.19276114731287047\n",
      "0.14469510992730866\n",
      "0.35585627492162736\n",
      "0.27668850967231107\n",
      "0.08758056249716338\n",
      "0.3540178283914189\n",
      "0.30595044741058064\n",
      "0.45107560153663856\n",
      "0.4812826986942604\n",
      "0.3718279194353837\n",
      "0.4561672778425597\n",
      "0.45320865661232745\n",
      "-0.06334295485507568\n",
      "0.014288645280818227\n",
      "0.6713213816961126\n",
      "0.6203817433455434\n",
      "0.6839440179423543\n",
      "0.4338082260478958\n",
      "0.5213868988238102\n",
      "0.5633302237405812\n",
      "0.23600426510025438\n",
      "0.018634536912717957\n",
      "0.14578680432824373\n",
      "0.3593016488083867\n",
      "0.16963139183196613\n",
      "0.3740458651284576\n",
      "0.3157053432458736\n",
      "0.1269910822486667\n",
      "0.15564472832716683\n",
      "0.06758075173651219\n",
      "0.09820600661663635\n",
      "0.000983883519341109\n",
      "0.5944312470020447\n",
      "0.5925577277582321\n",
      "0.7410296912973503\n",
      "0.5707791806338647\n",
      "0.45434276120528105\n",
      "0.5607928640840188\n",
      "0.5331768506004129\n",
      "0.430708268740825\n",
      "0.7073308837264447\n",
      "0.34482980712385014\n",
      "0.2610148758639352\n",
      "0.33123386956142076\n",
      "0.5101975096607985\n",
      "0.37301603267313416\n",
      "0.5193355284234319\n",
      "0.45710346407401575\n",
      "0.409247564631342\n",
      "0.6950031898339171\n",
      "0.6301218342732459\n",
      "0.07372149417237796\n",
      "0.03902875309982571\n",
      "0.23039830160171623\n",
      "0.2700901589132328\n",
      "0.11199459362055558\n",
      "0.514003487467153\n",
      "0.5175112947779693\n",
      "0.6011951774695925\n",
      "0.18530997707081537\n",
      "0.1356499905339644\n",
      "0.026515181306691355\n",
      "0.18278795280945007\n",
      "0.2842133688171248\n",
      "0.319557903974956\n",
      "0.5430070892917114\n",
      "0.4537403166212078\n",
      "0.7653764886721232\n",
      "0.35568255274501737\n",
      "0.13660222968312397\n",
      "0.03902875309982571\n",
      "0.3446488461889619\n",
      "0.2249757801927679\n",
      "0.23848867808891847\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "except_title = []\n",
    "for key in df_any['source'].drop_duplicates():\n",
    "    # print(key)\n",
    "    df_tmp = df_any[df_any['source'] == key]\n",
    "    a = df_tmp['STS']\n",
    "    b = df_tmp['tokens distance']\n",
    "    # print(pearsonr(a,b))\n",
    "    v,_ = spearmanr(a,b) \n",
    "    print(v)\n",
    "\n",
    "    a = df_tmp['title distance']\n",
    "    b = df_tmp['tokens distance']\n",
    "    # print(pearsonr(a,b))\n",
    "    v,_ = spearmanr(a,b) \n",
    "    print(v)\n",
    "\n",
    "    a = df_tmp['STS']\n",
    "    b = df_tmp['title distance']\n",
    "    # print(pearsonr(a,b))\n",
    "    v,_ = spearmanr(a,b) \n",
    "    # if np.isnan(v):\n",
    "    #     except_title.append(key)\n",
    "        # print(key)\n",
    "    print(v)\n",
    "    # break\n",
    "# except_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '01909ad2321613e2c455f004929a57c8', 'object': 'chat.completion', 'created': 1720584385, 'model': 'Qwen/Qwen2-7B-Instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Earth, officially known as Terra, is an incredible planet and the third planet in our solar system, residing in a distinct orbit around the sun. Uniquely, Earth is among the few celestial bodies in our solar system believed to harbor life, specifically because of the perfect climate conditions that support it. Earth is a few light-minutes away from the heart of the solar system, our star, making its temperature just right not to be scorched nor frozen, which is an indispensable ingredient for supporting life.\\n\\nThe flagship of Earth is its large, liquid water ocean, which envelops 71 percent of the planet\\'s surface. This water has had a deterring effect on solar heating and has served as a powerful promoter of Earth’s climate and ecological balance. The remaining part of our planet is either land, accommodating a wide diversity of terrestrial ecosystems, or undersea plains. The land is divided into continents and islands, supporting a plethora of life forms, and entirely covered or scattered by a myriad of water bodies.\\n\\nWhat is also unique about Earth\\'s atmosphere? Composed primarily of nitrogen and oxygen, this thin ‘shell\\' around our planet has cut back on the amount of sunlight reaching the earth, while at the same time providing the necessary elements for photosynthesis (the process by which plants convert light into energy), essential for the survival of virtually all plant and animal life.\\n\\nEarth is truly an anomalous \"blue jewel\" in the cosmos, and its incomparable life-forming conditions make it a true marvel of nature.'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 52, 'completion_tokens': 305, 'total_tokens': 357}, 'system_fingerprint': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Earth, officially known as Terra, is an incredible planet and the third planet in our solar system, residing in a distinct orbit around the sun. Uniquely, Earth is among the few celestial bodies in our solar system believed to harbor life, specifically because of the perfect climate conditions that support it. Earth is a few light-minutes away from the heart of the solar system, our star, making its temperature just right not to be scorched nor frozen, which is an indispensable ingredient for supporting life.\\n\\nThe flagship of Earth is its large, liquid water ocean, which envelops 71 percent of the planet\\'s surface. This water has had a deterring effect on solar heating and has served as a powerful promoter of Earth’s climate and ecological balance. The remaining part of our planet is either land, accommodating a wide diversity of terrestrial ecosystems, or undersea plains. The land is divided into continents and islands, supporting a plethora of life forms, and entirely covered or scattered by a myriad of water bodies.\\n\\nWhat is also unique about Earth\\'s atmosphere? Composed primarily of nitrogen and oxygen, this thin ‘shell\\' around our planet has cut back on the amount of sunlight reaching the earth, while at the same time providing the necessary elements for photosynthesis (the process by which plants convert light into energy), essential for the survival of virtually all plant and animal life.\\n\\nEarth is truly an anomalous \"blue jewel\" in the cosmos, and its incomparable life-forming conditions make it a true marvel of nature.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "def get_llm_article(title):\n",
    "\n",
    "    url = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"Qwen/Qwen2-7B-Instruct\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":  \"# You are an encyclopedia writer. \\n\"\n",
    "                            f\"Please write an article for *{title}* that is easy to understand and should be around 150 words long in English\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"Bearer sk-hxndleevlrdiygjlrfsnfgltpwwopommwquqnzdixrwrifxa\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            print(response.json())\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(response.text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return \"sorry! something went wrong\"\n",
    "\n",
    "    \n",
    "    \n",
    "get_llm_article(\"earth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再找一组例子测试\n",
    "Presidents_of_the_United_States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_list = set([\"John Adams\",\"John Quincy Adams\",\"Chester A. Arthur\",\"Joe Biden\",\"James Buchanan\",\"William Henry Harrison\", \"George H. W. Bush\",\"George W. Bush\",\"Jimmy Carter\",\"Grover Cleveland\",\"Bill Clinton\",\"Calvin Coolidge\",\"Dwight D. Eisenhower\",\"Millard Fillmore\",\"Gerald Ford\",\"James A. Garfield\",\"Ulysses S. Grant\",\"Warren G. Harding\",\"Benjamin Harrison\",\"Rutherford B. Hayes\",\"Herbert Hoover\",\"Andrew Jackson\",\"Thomas Jefferson\",\"Andrew Johnson\",\"Lyndon B. Johnson\",\"John F. Kennedy\",\"Abraham Lincoln\",\"James Madison\",\"William McKinley\",\"James Monroe\",\"Richard Nixon\",\"Barack Obama\",\"Franklin Pierce\",\"James K. Polk\",\"Ronald Reagan\",\"Franklin D. Roosevelt\",\"Theodore Roosevelt\",\"William Howard Taft\",\"Zachary Taylor\",\"Harry S. Truman\",\"Donald Trump\",\"John Tyler\",\"Martin Van Buren\",\"George Washington\",\"Woodrow Wilson\",])\n",
    "len(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_title(title):\n",
    "    driver = neo4j.GraphDatabase.driver(\n",
    "            \"bolt://192.168.1.227:17688\",\n",
    "            auth=(\"neo4j\", \"neo4j-test\"),\n",
    "        )\n",
    "    record_list = []\n",
    "    with driver.session(database=\"enwiki\") as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (start:page {f_title: $source})-[r:page]->(end:page) \"\n",
    "            \"RETURN start.pageId as SID, end.f_title as title, end.pageId as EID \"\n",
    "            ,\n",
    "            source=title,\n",
    "        )\n",
    "        for record in result:\n",
    "            record_list.append(record)\n",
    "\n",
    "    return record_list\n",
    "\n",
    "title_set = set()\n",
    "for title in category_list:\n",
    "    for record in query_title(title):\n",
    "        title_set.add((title, int(record[\"SID\"])))\n",
    "        # title_set.add((record[\"title\"], int(record[\"EID\"])))\n",
    "len(title_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [1:59:12<00:00, 158.94s/it]  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "result_list_p2 = []\n",
    "\n",
    "title_data_list = list(title_set)\n",
    "\n",
    "\n",
    "tmp_list = title_set\n",
    "print(len(tmp_list))\n",
    "\n",
    "for title_a, ID_a in tqdm.tqdm(tmp_list):\n",
    "    for title_b, ID_b in tmp_list:\n",
    "        if title_a == title_b:\n",
    "            continue\n",
    "        \n",
    "        plaintext_a = get_plaintext(ID_a)\n",
    "        plaintext_b = get_plaintext(ID_b)\n",
    "        \n",
    "        if not plaintext_a or not plaintext_b:\n",
    "            continue\n",
    "        \n",
    "        token_set_1, _ = get_token(plaintext_a)\n",
    "        token_set_2, _ = get_token(plaintext_b)\n",
    "        \n",
    "        df, _ = calculate_cartesian_product_distances(\n",
    "                    tuple(token_set_1 - token_set_2), \n",
    "                    tuple(token_set_2 - token_set_1),\n",
    "                    tuple(token_set_2 & token_set_1),\n",
    "                )\n",
    "        if len(df):\n",
    "            result_list_p2.append({\n",
    "                \"source\": title_a,\n",
    "                \"dest\": title_b,\n",
    "                \"title distance\": query_partner_distancles(ID_a, ID_b),\n",
    "                \"tokens distance\": df['distance'].mean().round(4),\n",
    "                \"STS\": calculate_similarity(plaintext_a, plaintext_b)\n",
    "            })\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>dest</th>\n",
       "      <th>google similarity</th>\n",
       "      <th>token similarity</th>\n",
       "      <th>STS similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James A. Garfield</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>0.636485</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.347201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James A. Garfield</td>\n",
       "      <td>John Tyler</td>\n",
       "      <td>0.737854</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.437931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James A. Garfield</td>\n",
       "      <td>James Monroe</td>\n",
       "      <td>0.725755</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.409478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James A. Garfield</td>\n",
       "      <td>Richard Nixon</td>\n",
       "      <td>0.575057</td>\n",
       "      <td>0.5362</td>\n",
       "      <td>0.339013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>James A. Garfield</td>\n",
       "      <td>Warren G. Harding</td>\n",
       "      <td>0.762793</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>John Quincy Adams</td>\n",
       "      <td>0.629134</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.447842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>0.573534</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.350501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>William McKinley</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.5137</td>\n",
       "      <td>0.420271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>Zachary Taylor</td>\n",
       "      <td>0.600656</td>\n",
       "      <td>0.5596</td>\n",
       "      <td>0.392882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>William Howard Taft</td>\n",
       "      <td>0.570261</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.382317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1816 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source                   dest  google similarity  \\\n",
       "0     James A. Garfield     Theodore Roosevelt           0.636485   \n",
       "1     James A. Garfield             John Tyler           0.737854   \n",
       "3     James A. Garfield           James Monroe           0.725755   \n",
       "4     James A. Garfield          Richard Nixon           0.575057   \n",
       "5     James A. Garfield      Warren G. Harding           0.762793   \n",
       "...                 ...                    ...                ...   \n",
       "1975  George Washington      John Quincy Adams           0.629134   \n",
       "1976  George Washington  Franklin D. Roosevelt           0.573534   \n",
       "1977  George Washington       William McKinley           0.566138   \n",
       "1978  George Washington         Zachary Taylor           0.600656   \n",
       "1979  George Washington    William Howard Taft           0.570261   \n",
       "\n",
       "      token similarity  STS similarity  \n",
       "0               0.5889        0.347201  \n",
       "1               0.5961        0.437931  \n",
       "3               0.5866        0.409478  \n",
       "4               0.5362        0.339013  \n",
       "5               0.6210        0.568400  \n",
       "...                ...             ...  \n",
       "1975            0.5750        0.447842  \n",
       "1976            0.5478        0.350501  \n",
       "1977            0.5137        0.420271  \n",
       "1978            0.5596        0.392882  \n",
       "1979            0.5559        0.382317  \n",
       "\n",
       "[1816 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_ok_p2 = pd.DataFrame(result_list_p2)\n",
    "# df_ok_p2.to_csv(\"./tmp.csv\")\n",
    "\n",
    "df_any = df_ok_p2.fillna(1, inplace=False)\n",
    "df_any = df_any.rename(columns={'title distance': 'google similarity', \n",
    "                                'tokens distance': 'token similarity',\n",
    "                                'STS': 'STS similarity',\n",
    "                                })\n",
    "\n",
    "# df_any = df_any[~df_any['source'].isin(except_row)]\n",
    "df_any['google similarity'] = 1 - df_any['google similarity']\n",
    "df_any['token similarity'] = 1 - df_any['token similarity']\n",
    "df_any.to_csv(\"../model/score_president.csv\", index=False)\n",
    "df_any[df_any['google similarity'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from modelscope import AutoModel\n",
    "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine 0.47387356350132315\n",
      "euclidean 3.5670745372772217\n",
      "minkowski 3.5670745372772217\n",
      "cityblock 77.864235\n",
      "chebyshev 0.38387686\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import (\n",
    "    cosine,\n",
    "    euclidean,\n",
    "    minkowski,\n",
    "    cityblock,\n",
    "    chebyshev,\n",
    ")\n",
    "\n",
    "from numpy.linalg import norm\n",
    "cos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n",
    "\n",
    "a = [1,2,3,4,5,6]\n",
    "b = [11,22,33,44,55,66]\n",
    "a,b = model.encode([\"今天天气不错\", \"今天天气绝对不是非常不错,\"])\n",
    "# a,b = calculate_similarity(plaintext_a, plaintext_b)\n",
    "for func in [cosine, euclidean, minkowski,cityblock,chebyshev]:\n",
    "    \n",
    "    print(func.__name__, func(a, b))\n",
    "# cos_sim(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: a, Value: 1.23\n",
      "Key: b, Value: 0.414145\n",
      "Key: c, Value: -0.51413526\n",
      "Key: d, Value: None\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "connection_pool = redis.ConnectionPool(host='192.168.1.227', port=6379, db=0)\n",
    "\n",
    "# 创建 Redis 客户端实例，使用上面创建的连接池\n",
    "r = redis.Redis(connection_pool=connection_pool,decode_responses=True)\n",
    "# 定义一批键\n",
    "keys = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# 使用 mget 命令批量查询\n",
    "values = r.mget(keys)\n",
    "\n",
    "# 打印结果\n",
    "for key, value in zip(keys, values):\n",
    "    print(f\"Key: {key}, Value: {float(value) if value  else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'a': 1.23,\n",
    "    'b': 0.414145,\n",
    "    'c': -.51413526\n",
    "}\n",
    "r.mset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_name = \"test_stream\"\n",
    "consumer_name = 'my_consumer'\n",
    "group_name = 'my_group'\n",
    "for i in range(1,3):\n",
    "    r.xadd(stream_name, {\"a\": i, \"b\": i})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message b'1721094328313-0' with data: {b'_id': b'1040533-609303', b'SID': b'1040533', b'Stitle': b'Martin_McDonagh', b'EID': b'609303', b'Etitle': b'Nicholas_Hytner', b'weight': b'0.34160003850600884'}\n",
      "Received message b'1721094328314-0' with data: {b'_id': b'893454-4287791', b'SID': b'893454', b'Stitle': b'Frank_Langella', b'EID': b'4287791', b'Etitle': b'Kathryn_Hahn', b'weight': b'0.34160003850600884'}\n",
      "Received message b'1721094328314-1' with data: {b'_id': b'21643854-40186398', b'SID': b'21643854', b'Stitle': b'Far_East_Movement', b'EID': b'40186398', b'Etitle': b'Roar_(song)', b'weight': b'0.34160003850600884'}\n",
      "Received message b'1721094328314-2' with data: {b'_id': b'394815-3601630', b'SID': b'394815', b'Stitle': b'Introduced_species', b'EID': b'3601630', b'Etitle': b\"Townsend's_solitaire\", b'weight': b'0.34160006720832875'}\n",
      "Received message b'1721094328314-3' with data: {b'_id': b'62266-129585', b'SID': b'62266', b'Stitle': b'William_Wyler', b'EID': b'129585', b'Etitle': b'Dances_with_Wolves', b'weight': b'0.34160008180433205'}\n",
      "Received message b'1721094328314-4' with data: {b'_id': b'27179061-43416811', b'SID': b'27179061', b'Stitle': b'Yelawolf', b'EID': b'43416811', b'Etitle': b'Empire_Distribution', b'weight': b'0.34160008180433205'}\n",
      "Received message b'1721094328314-5' with data: {b'_id': b'21221640-215788', b'SID': b'21221640', b'Stitle': b'Xzibit', b'EID': b'215788', b'Etitle': b'Brand_Nubian', b'weight': b'0.3416000926695209'}\n",
      "Received message b'1721094328314-6' with data: {b'_id': b'1928850-35198122', b'SID': b'1928850', b'Stitle': b'John_Roberts', b'EID': b'35198122', b'Etitle': b'National_Federation_of_Independent_Business_v._Sebelius', b'weight': b'0.3416001321897922'}\n",
      "Received message b'1721094328315-0' with data: {b'_id': b'115037-115079', b'SID': b'115037', b'Stitle': b'Danville,_Kentucky', b'EID': b'115079', b'Etitle': b'Carrollton,_Kentucky', b'weight': b'0.3416001321897922'}\n",
      "Received message b'1721094328315-1' with data: {b'_id': b'12347964-8231037', b'SID': b'12347964', b'Stitle': b'FK_Napredak_Kru\\xc5\\xa1evac', b'EID': b'8231037', b'Etitle': b'1998\\xe2\\x80\\x9399_First_League_of_FR_Yugoslavia', b'weight': b'0.3416001321897922'}\n",
      "Received message b'1721094328315-2' with data: {b'_id': b'8312977-21336437', b'SID': b'8312977', b'Stitle': b'Fashion_show', b'EID': b'21336437', b'Etitle': b'Haute_couture', b'weight': b'0.3416001665542181'}\n",
      "Received message b'1721094328315-3' with data: {b'_id': b'689493-10189546', b'SID': b'689493', b'Stitle': b'FK_Sarajevo', b'EID': b'10189546', b'Etitle': b'Zlatko_Vujovi\\xc4\\x87', b'weight': b'0.3416001933087767'}\n",
      "Received message b'1721094328315-4' with data: {b'_id': b'378032-446837', b'SID': b'378032', b'Stitle': b'Parliament_of_Great_Britain', b'EID': b'446837', b'Etitle': b'1865_United_Kingdom_general_election', b'weight': b'0.34160020654358314'}\n",
      "Received message b'1721094328315-5' with data: {b'_id': b'1017193-43923', b'SID': b'1017193', b'Stitle': b'Michael_Hamburger', b'EID': b'43923', b'Etitle': b'Philip_Larkin', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-6' with data: {b'_id': b'11406665-6006557', b'SID': b'11406665', b'Stitle': b'March_of_Pannonia', b'EID': b'6006557', b'Etitle': b'Kingdom_of_Italy_(Holy_Roman_Empire)', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-7' with data: {b'_id': b'6167451-1690020', b'SID': b'6167451', b'Stitle': b'Holy_Moses', b'EID': b'1690020', b'Etitle': b'Skid_Row_(American_band)', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-8' with data: {b'_id': b'866593-2381490', b'SID': b'866593', b'Stitle': b'HBO_Films', b'EID': b'2381490', b'Etitle': b'Jordan_Ladd', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-9' with data: {b'_id': b'866593-2942397', b'SID': b'866593', b'Stitle': b'HBO_Films', b'EID': b'2942397', b'Etitle': b'Sacha_Gervasi', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-10' with data: {b'_id': b'4001321-3076353', b'SID': b'4001321', b'Stitle': b'Prabhu_Deva', b'EID': b'3076353', b'Etitle': b'Autograph_(2004_film)', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-11' with data: {b'_id': b'4001321-44875573', b'SID': b'4001321', b'Stitle': b'Prabhu_Deva', b'EID': b'44875573', b'Etitle': b'Dishoom', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-12' with data: {b'_id': b'342780-72122928', b'SID': b'342780', b'Stitle': b'Citizens_Bank_Park', b'EID': b'72122928', b'Etitle': b'2023_Houston_Astros_season', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328315-13' with data: {b'_id': b'1433800-164236', b'SID': b'1433800', b'Stitle': b'Quintus_Caecilius_Metellus_Numidicus', b'EID': b'164236', b'Etitle': b'Valerius_Maximus', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-0' with data: {b'_id': b'416641-28731287', b'SID': b'416641', b'Stitle': b'Jason_Isaacs', b'EID': b'28731287', b'Etitle': b'Robert_Clotworthy', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-1' with data: {b'_id': b'416641-55742666', b'SID': b'416641', b'Stitle': b'Jason_Isaacs', b'EID': b'55742666', b'Etitle': b'Asher_Angel', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-2' with data: {b'_id': b'524276-2381490', b'SID': b'524276', b'Stitle': b'Gary_Sinise', b'EID': b'2381490', b'Etitle': b'Jordan_Ladd', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-3' with data: {b'_id': b'524276-2600885', b'SID': b'524276', b'Stitle': b'Gary_Sinise', b'EID': b'2600885', b'Etitle': b'Dale_Midkiff', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-4' with data: {b'_id': b'528951-8074727', b'SID': b'528951', b'Stitle': b'Tambov', b'EID': b'8074727', b'Etitle': b'Lenin_Stadium_(Khabarovsk)', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-5' with data: {b'_id': b'328144-10949060', b'SID': b'328144', b'Stitle': b'Cabaret_(musical)', b'EID': b'10949060', b'Etitle': b'52nd_Tony_Awards', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-6' with data: {b'_id': b'1052978-703049', b'SID': b'1052978', b'Stitle': b'Senate_of_Puerto_Rico', b'EID': b'703049', b'Etitle': b'Ponce_massacre', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-7' with data: {b'_id': b'164236-29191024', b'SID': b'164236', b'Stitle': b'Valerius_Maximus', b'EID': b'29191024', b'Etitle': b'Andrew_Lintott', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-8' with data: {b'_id': b'356028-1110142', b'SID': b'356028', b'Stitle': b'Felix_Frankfurter', b'EID': b'1110142', b'Etitle': b'Laurence_Silberman', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-9' with data: {b'_id': b'11958301-51776639', b'SID': b'11958301', b'Stitle': b'BWF_Grand_Prix_Gold_and_Grand_Prix', b'EID': b'51776639', b'Etitle': b'Kim_Bruun', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-10' with data: {b'_id': b'11958301-51425567', b'SID': b'11958301', b'Stitle': b'BWF_Grand_Prix_Gold_and_Grand_Prix', b'EID': b'51425567', b'Etitle': b'Nikita_Khakimov', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-11' with data: {b'_id': b'1972815-19456657', b'SID': b'1972815', b'Stitle': b'1999_Wimbledon_Championships', b'EID': b'19456657', b'Etitle': b'2001_ATP_Tour', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-12' with data: {b'_id': b'15174105-30848631', b'SID': b'15174105', b'Stitle': b'Youku', b'EID': b'30848631', b'Etitle': b'Scarlet_Heart', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-13' with data: {b'_id': b'981691-6154715', b'SID': b'981691', b'Stitle': b'Cashel,_County_Tipperary', b'EID': b'6154715', b'Etitle': b'Mullinahone_GAA', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328316-14' with data: {b'_id': b'981691-1019636', b'SID': b'981691', b'Stitle': b'Cashel,_County_Tipperary', b'EID': b'1019636', b'Etitle': b'Newmarket-on-Fergus', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-0' with data: {b'_id': b'17288160-2975576', b'SID': b'17288160', b'Stitle': b'The_Smurfs_(1981_TV_series)', b'EID': b'2975576', b'Etitle': b'Invasion_America', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-1' with data: {b'_id': b'17288160-5055956', b'SID': b'17288160', b'Stitle': b'The_Smurfs_(1981_TV_series)', b'EID': b'5055956', b'Etitle': b\"Tweety's_High-Flying_Adventure\", b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-2' with data: {b'_id': b'17288160-454694', b'SID': b'17288160', b'Stitle': b'The_Smurfs_(1981_TV_series)', b'EID': b'454694', b'Etitle': b'Beverly_Hills_Teens', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-3' with data: {b'_id': b'2498018-6598982', b'SID': b'2498018', b'Stitle': b'FC_Sportul_Studen\\xc8\\x9besc_Bucure\\xc8\\x99ti', b'EID': b'6598982', b'Etitle': b'CF_Liberty_Oradea', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-4' with data: {b'_id': b'15556268-50554192', b'SID': b'15556268', b'Stitle': b'Chunsa_Film_Art_Awards', b'EID': b'50554192', b'Etitle': b'Kim_Tae-ri', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-5' with data: {b'_id': b'30923526-12069414', b'SID': b'30923526', b'Stitle': b'Raheem_Sterling', b'EID': b'12069414', b'Etitle': b'\\xc3\\x80ngel_Rangel', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-6' with data: {b'_id': b'30923526-51278339', b'SID': b'30923526', b'Stitle': b'Raheem_Sterling', b'EID': b'51278339', b'Etitle': b'Domingos_Quina', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-7' with data: {b'_id': b'5735997-54628900', b'SID': b'5735997', b'Stitle': b'Football_Association_of_Thailand', b'EID': b'54628900', b'Etitle': b'Razlan_Joffri_Ali', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-8' with data: {b'_id': b'52067854-8856356', b'SID': b'52067854', b'Stitle': b'Elena_Prus', b'EID': b'8856356', b'Etitle': b'French_Open_(badminton)', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-9' with data: {b'_id': b'8856356-11945017', b'SID': b'8856356', b'Stitle': b'French_Open_(badminton)', b'EID': b'11945017', b'Etitle': b'Dong_Jiong', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-10' with data: {b'_id': b'5747191-22492938', b'SID': b'5747191', b'Stitle': b'Kosovo_national_football_team', b'EID': b'22492938', b'Etitle': b'Albania_national_under-20_football_team', b'weight': b'0.3416002151876446'}\n",
      "Received message b'1721094328317-11' with data: {b'_id': b'21492915-20988688', b'SID': b'21492915', b'Stitle': b'Australasia', b'EID': b'20988688', b'Etitle': b'Eastern_yellow_wagtail', b'weight': b'0.34160022123368783'}\n",
      "Received message b'1721094328317-12' with data: {b'_id': b'1624-632122', b'SID': b'1624', b'Stitle': b'Andrew_Johnson', b'EID': b'632122', b'Etitle': b'Reconstruction_Acts', b'weight': b'0.34160022123368783'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for stream, messages in r.xread({stream_name:\"0-0\"}, count=50,block=5000):\n",
    "    for message_id, message in messages:\n",
    "        print(f'Received message {message_id} with data: {message}')\n",
    "        # print(message[b\"a\"])\n",
    "        # r.xack(stream_name, \"\", message_id)\n",
    "        # r.xdel(stream_name, message_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'my_group'\n",
    "try:\n",
    "    # r.xgroup_create(stream_name, group_name, id='0', mkstream=True)\n",
    "    r.xgroup_create(stream_name, group_name, mkstream=True)\n",
    "except redis.exceptions.ResponseError as e:\n",
    "    # 如果组已经存在，则忽略错误\n",
    "    if \"BUSYGROUP Consumer Group name already exists\" not in str(e):\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Error reading messages: NOGROUP No such key 'task_0' or consumer group 'my_group_1' in XREADGROUP with GROUP option\n"
     ]
    }
   ],
   "source": [
    "consumer_name = 'myconsumer'\n",
    "while True:\n",
    "    try:\n",
    "        print(1)\n",
    "        messages = r.xreadgroup(group_name, consumer_name, {stream_name: '>'}, count=100, block=1000)\n",
    "        for stream, msgs in messages:\n",
    "            for msg_id, msg_data in msgs:\n",
    "                print(f\"Message ID: {msg_id}, Message Data: {msg_data}\")\n",
    "                # 在处理完消息后，可以确认消息已被处理\n",
    "                r.xack(stream_name, group_name, msg_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading messages: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection = DATABASE.token_mathch_v20240712\n",
    "\n",
    "import functools\n",
    "import time\n",
    "\n",
    "def tt(v):\n",
    "    time.sleep(1)\n",
    "    print(v)\n",
    "    return v\n",
    "\n",
    "tt = functools.lru_cache(maxsize=5)(tt)\n",
    "\n",
    "tt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m         messages \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxreadgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsumer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mstream_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0-0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m messages:\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo new messages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/redis/commands/core.py:4008\u001b[0m, in \u001b[0;36mStreamCommands.xreadgroup\u001b[0;34m(self, groupname, consumername, streams, count, block, noack)\u001b[0m\n\u001b[1;32m   4006\u001b[0m pieces\u001b[38;5;241m.\u001b[39mextend(streams\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   4007\u001b[0m pieces\u001b[38;5;241m.\u001b[39mextend(streams\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m-> 4008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mXREADGROUP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpieces\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/redis/client.py:545\u001b[0m, in \u001b[0;36mRedis.execute_command\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m    542\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mor\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mget_connection(command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_command_parse_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disconnect_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection:\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/redis/retry.py:46\u001b[0m, in \u001b[0;36mRetry.call_with_retry\u001b[0;34m(self, do, fail)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supported_errors \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     48\u001b[0m         failures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/redis/client.py:546\u001b[0m, in \u001b[0;36mRedis.execute_command.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    542\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mor\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mget_connection(command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39mcall_with_retry(\n\u001b[0;32m--> 546\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_command_parse_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m error: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disconnect_raise(conn, error),\n\u001b[1;32m    550\u001b[0m     )\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection:\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/redis/client.py:521\u001b[0m, in \u001b[0;36mRedis._send_command_parse_response\u001b[0;34m(self, conn, command_name, *args, **options)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_send_command_parse_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, command_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Send a command and parse the response\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 521\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_response(conn, command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/redis/connection.py:476\u001b[0m, in \u001b[0;36mAbstractConnection.send_command\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    475\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pack and send a command to the Redis server\"\"\"\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_packed_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_command_packer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_health\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheck_health\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/redis/connection.py:454\u001b[0m, in \u001b[0;36mAbstractConnection.send_packed_command\u001b[0;34m(self, command, check_health)\u001b[0m\n\u001b[1;32m    452\u001b[0m         command \u001b[38;5;241m=\u001b[39m [command]\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m command:\n\u001b[0;32m--> 454\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisconnect()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "consumer_name = f\"consumer-1\"\n",
    "group_name = 'my_group'\n",
    "stream_name = 'task_0'\n",
    "# r.xgroup_create(stream_name, group_name, mkstream=True)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        messages = r.xreadgroup(group_name, consumer_name, {stream_name: '0-0'}, count=1, block=1000)\n",
    "        if not messages:\n",
    "            print(\"No new messages\")\n",
    "            break\n",
    "        for stream, msgs in messages:\n",
    "            for msg_id, msg_data in msgs:\n",
    "                # yield msg_id, msg_data\n",
    "                print(f\"Message ID: {msg_id}, Message Data: {msg_data}\")\n",
    "                # time.sleep(1)\n",
    "                # 在处理完消息后，可以确认消息已被处理\n",
    "                # r.xack(stream_name, group_name, msg_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading messages: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.xpending(stream_name, group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../gpc_demo\") \n",
    "sys.path.append(\"..\") \n",
    "from utils import (\n",
    "    query_distance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27298083, 36645032, 0.5266786),\n",
       " (18963910, 27298083, 0.65231186),\n",
       " (18963910, 36645032, 0.7101743),\n",
       " (18963910, 27298083, 0.65231186),\n",
       " (18963910, 36645032, 0.7101743),\n",
       " (27298083, 36645032, 0.5266786)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query_distance((123131,51235214,27298083,36645032,18963910 ),(18963910 ,123131,51235214,27298083,36645032))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
